{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 3\n",
    "#### Student Names and Student Id : Akshay Rai Chopra(30228751) and  Parul (29507960)\n",
    "#### Group Number: 154\n",
    "\n",
    "\n",
    "Date: 04/10/2019\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 2.7.11 and Jupyter notebook\n",
    "\n",
    "## Introduction:\n",
    "### Data Cleansing\n",
    "Data cleansing is an iterative process. The first step of the cleansing process is data auditing. In this step, we identify the types of anomalies that reduce the data quality.  Data auditing is about programmatically checking the data using some validation rules that are pre-specified, and then creating a report of the quality of the data and its problems. We often apply some statistical tests in this step for examining the data.\n",
    "Data Anomalies can be classified at a high level into three categories:\n",
    "\n",
    "1. **Syntactic Anomalies**: \n",
    "describe characteristics concerning the format and values used for representation of the entities. Syntactic anomalies such as: lexical errors, domain format errors, syntactical error and irregularities.\n",
    "2. **Semantic Anomalies**: \n",
    "hinder the data collection from being a comprehensive and non-redundant representation of the mini-world. These types of anomalies include: Integrity constraint violations, contradictions, duplicates and invalid tuples\n",
    "3. **Coverage Anomalies**: \n",
    "decrease the amount of entities and entity properties from the mini-world that are represented in the data collection. Coverage anomalies are categorized as: missing values and missing tuples\n",
    "\n",
    "\n",
    "\"Group154_dirty_data.csv\" - The dirty data which have different type of errors and we need to detect and fix them.\n",
    "\n",
    "\"Group154_outlier_data.csv\" - The data which have outlier w.r.t delivery fee column, we need to remove the rows that have outliers\n",
    "\n",
    "\"Group154_missing_data.csv\" - The data which have missing values and we need to impute them correctly.\n",
    "\n",
    "The dataset contains Food Delivery data from a restaurant in Melbourne, Australia. The restaurant has three branches around CBD area. All three branches share the same menu but they have different management so they operate differently.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "For the assignment we use a number of libraries to help us process and fix the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> As a first step we load the data using Pandas library and store them in the respective dataframes by \"pd.read_csv()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data = pd.read_csv(\"Group154_dirty_data.csv\")\n",
    "outlier_data = pd.read_csv(\"Group154_outlier_data.csv\")\n",
    "missing_data = pd.read_csv(\"Group154_missing_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly we will fix the errors in Dirty_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 12)\n"
     ]
    }
   ],
   "source": [
    "print(dirty_data.shape) # .shape tells the number of rows and columns in the dateframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 500 rows(observations) and 15 columns(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      "order_id                   500 non-null object\n",
      "date                       500 non-null object\n",
      "time                       500 non-null object\n",
      "order_type                 500 non-null object\n",
      "branch_code                500 non-null object\n",
      "order_items                500 non-null object\n",
      "order_price                500 non-null float64\n",
      "customer_lat               500 non-null float64\n",
      "customer_lon               500 non-null float64\n",
      "customerHasloyalty?        500 non-null int64\n",
      "distance_to_customer_KM    500 non-null float64\n",
      "delivery_fee               500 non-null float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dirty_data.info() # .info() gives an insight about which features are categorical and which are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>511.842300</td>\n",
       "      <td>-30.753763</td>\n",
       "      <td>143.503721</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>8.739410</td>\n",
       "      <td>13.813120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>266.651019</td>\n",
       "      <td>25.336331</td>\n",
       "      <td>16.298857</td>\n",
       "      <td>0.325287</td>\n",
       "      <td>1.600082</td>\n",
       "      <td>2.539826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>45.250000</td>\n",
       "      <td>-37.828216</td>\n",
       "      <td>-37.819026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.271000</td>\n",
       "      <td>4.499288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>302.812500</td>\n",
       "      <td>-37.817794</td>\n",
       "      <td>144.950582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.813250</td>\n",
       "      <td>12.631459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>465.350000</td>\n",
       "      <td>-37.811639</td>\n",
       "      <td>144.963488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.792000</td>\n",
       "      <td>14.006261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>683.500000</td>\n",
       "      <td>-37.804107</td>\n",
       "      <td>144.978716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.848750</td>\n",
       "      <td>15.300665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1520.000000</td>\n",
       "      <td>144.976883</td>\n",
       "      <td>145.016633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.043000</td>\n",
       "      <td>21.119195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_price  customer_lat  customer_lon  customerHasloyalty?  \\\n",
       "count   500.000000    500.000000    500.000000           500.000000   \n",
       "mean    511.842300    -30.753763    143.503721             0.120000   \n",
       "std     266.651019     25.336331     16.298857             0.325287   \n",
       "min      45.250000    -37.828216    -37.819026             0.000000   \n",
       "25%     302.812500    -37.817794    144.950582             0.000000   \n",
       "50%     465.350000    -37.811639    144.963488             0.000000   \n",
       "75%     683.500000    -37.804107    144.978716             0.000000   \n",
       "max    1520.000000    144.976883    145.016633             1.000000   \n",
       "\n",
       "       distance_to_customer_KM  delivery_fee  \n",
       "count               500.000000    500.000000  \n",
       "mean                  8.739410     13.813120  \n",
       "std                   1.600082      2.539826  \n",
       "min                   3.271000      4.499288  \n",
       "25%                   7.813250     12.631459  \n",
       "50%                   8.792000     14.006261  \n",
       "75%                   9.848750     15.300665  \n",
       "max                  13.043000     21.119195  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.describe() # .describe() tells the distribution(statisitcs) of numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation tells us that:\n",
    "\n",
    "* Total samples are 500\n",
    "* customerHasloyalty?  is a categorical feature with 0 or 1 values.\n",
    "* Max of customer_lat is 144 and which is not in the range of latitudes\n",
    "* Min of customer_lon is -37 and which is not in the range of longitudes\n",
    "* order price has a maximum value of 1520, it is strange ( possibly an error )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>500</td>\n",
       "      <td>303</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ORDB08554</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>18:08:27</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salad', 6), ('Chicken', 10)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>170</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id        date      time order_type branch_code  \\\n",
       "count         500         500       500        500         500   \n",
       "unique        500         303        72          3           6   \n",
       "top     ORDB08554  2018-10-31  18:08:27      Lunch          TP   \n",
       "freq            1           5        12        170         163   \n",
       "\n",
       "                            order_items  \n",
       "count                               500  \n",
       "unique                              497  \n",
       "top     [('Salad', 6), ('Chicken', 10)]  \n",
       "freq                                  2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.describe(include=['O']) #distribution of categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the table above tells us:\n",
    "\n",
    "* branch_code variable has 6 possible values but we are provided with the info that there are only 3 branches.\n",
    "* Order_type has only 3 values, lunch, breakfast and dinner with count of Lunch being 170 times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the branch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP    163\n",
       "BK    155\n",
       "NS    149\n",
       "ns     14\n",
       "tp     10\n",
       "bk      9\n",
       "Name: branch_code, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.branch_code.value_counts() #.value_counts return a series containing counts of unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lexical error (syntactic anomaly) - branch_code can only take 3 values since there are only 3 branches. We can clearly infer that ns means NS, tp means TP and bk means BK. So we will fix this error but before that we try to see if the branch_code has any relation wtih order_id, so we use the data present in outlier to see any kind of relation since there zre no errors in the outlier_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns_o_list -  {'ORDZ', 'ORDC', 'ORDI'}\n",
      "tp_o_list -  {'ORDY', 'ORDB', 'ORDJ'}\n",
      "bk_o_list -  {'ORDA', 'ORDX', 'ORDK'}\n"
     ]
    }
   ],
   "source": [
    "# creating 3 emoty lists\n",
    "ns_o_list=[]\n",
    "tp_o_list=[]\n",
    "bk_o_list=[]\n",
    "\n",
    "\n",
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "for a,b in outlier_data.iterrows(): \n",
    "    b_code=b['branch_code'] # saving each branch_code in b_code\n",
    "    o_id=b['order_id']      # saving each order_id in o_id \n",
    "    \n",
    "    \n",
    "    #if the branch code is NS, appending the first 4 characters of order_id in ns_o_list \n",
    "    if b_code =='NS':\n",
    "        ns_o_list.append(o_id[0:4])\n",
    "        \n",
    "    #if the branch code is TP, appending the first 4 characters of order_id in tp_o_list    \n",
    "    if b_code =='TP':\n",
    "        tp_o_list.append(o_id[0:4])\n",
    "        \n",
    "    #if the branch code is BK, appending the first 4 characters of order_id in bk_o_list\n",
    "    if b_code =='BK':\n",
    "        bk_o_list.append(o_id[0:4])\n",
    "    \n",
    "#using set on the list will give the distinct values of corresponding order_ids\n",
    "print('ns_o_list - ', set(ns_o_list)) \n",
    "print('tp_o_list - ', set(tp_o_list))\n",
    "print('bk_o_list - ', set(bk_o_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there is a relation between order_id and branch_code and we will see if there are any errors regarding this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>branch_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORDJ07617</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORDY05853</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORDI02968</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORDY06446</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORDZ01045</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORDA06887</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORDB08630</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORDZ09998</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORDY01587</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORDZ05882</td>\n",
       "      <td>tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORDC05125</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORDB01134</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORDC10200</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORDI07395</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORDX07459</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORDY05546</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ORDB05011</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORDB08109</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORDB08390</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORDX09527</td>\n",
       "      <td>tp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_id branch_code\n",
       "0   ORDJ07617          TP\n",
       "1   ORDY05853          TP\n",
       "2   ORDI02968          NS\n",
       "3   ORDY06446          TP\n",
       "4   ORDZ01045          NS\n",
       "5   ORDA06887          BK\n",
       "6   ORDB08630          TP\n",
       "7   ORDZ09998          NS\n",
       "8   ORDY01587          TP\n",
       "9   ORDZ05882          tp\n",
       "10  ORDC05125          NS\n",
       "11  ORDB01134          TP\n",
       "12  ORDC10200          NS\n",
       "13  ORDI07395          NS\n",
       "14  ORDX07459          BK\n",
       "15  ORDY05546          TP\n",
       "16  ORDB05011          TP\n",
       "17  ORDB08109          TP\n",
       "18  ORDB08390          TP\n",
       "19  ORDX09527          tp"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data[['order_id','branch_code']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the 9th and 19th row , ORDZ05882 should belong to NS but is assigned to tp, whereas ORDX09527 should belong to BK but is assigned to tp. Another thing , correcting these errors might fix the lexical error we found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "\n",
    "for x,y in dirty_data.iterrows():\n",
    "    o_id = y['order_id'] # saving each order_id in o_id\n",
    "    b_code = y['branch_code'] # saving each branch_code in b_code\n",
    "    \n",
    "    \n",
    "    # if the first 4 characters of order_id are in the ns_o_list we created above, then \n",
    "    # we check another if condition that if b_code is not equal to 'NS\n",
    "    # then assign the value 'NS' to it \n",
    "    # iloc[x,4] means the datavalue with x as the index of the row and 4 means the column 'branch_code'\n",
    "    if o_id[0:4] in ns_o_list:\n",
    "        if b_code!= 'NS':\n",
    "            dirty_data.iloc[x,4] = 'NS'\n",
    "            \n",
    "    # if the first 4 characters of order_id are in the tp_o_list we created above, then \n",
    "    # we check another if condition that if b_code is not equal to 'TP'\n",
    "    # then assign the value 'TP' to it \n",
    "    # iloc[x,4] means the datavalue with x as the index of the row and 4 means the column 'branch_code'        \n",
    "    elif o_id[0:4] in tp_o_list:\n",
    "        if b_code!= 'TP':\n",
    "            dirty_data.iloc[x,4] = 'TP'\n",
    "    \n",
    "    # if the first 4 characters of order_id are in the bk_o_list we created above, then \n",
    "    # we check another if condition that if b_code is not equal to 'BK'\n",
    "    # then assign the value 'BK' to it \n",
    "    # iloc[x,4] means the datavalue with x as the index of the row and 4 means the column 'branch_code'\n",
    "    elif o_id[0:4] in bk_o_list:\n",
    "        if b_code!= 'BK':\n",
    "            dirty_data.iloc[x,4] = 'BK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP    172\n",
       "BK    165\n",
       "NS    163\n",
       "Name: branch_code, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.branch_code.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the errors in the brancg_code are now fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the format of Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2018-08-17\n",
       "1    2018-06-26\n",
       "2    2018-01-26\n",
       "3    2018-06-24\n",
       "4    2018-10-02\n",
       "5    11-03-2018\n",
       "6    2018-11-26\n",
       "7    2018-07-16\n",
       "8    2018-03-26\n",
       "9    2018-11-14\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.date.head(10) #seeing the first 10 values of column 'date' using .head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the date is not consistent. Most of the values have yyyy-mm-dd format and there are some with mm-dd-yyyy or dd-mm-yyyy format which needs to be fixed. This is another syntactic error.\n",
    "\n",
    "We first find out the dates which are in correct format or incoorect format with the help pf regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_date1= re.compile(r\"(\\d{4})-(\\d{2})-(\\d{2})\") #it matches the date in yyyy-mm-dd or yyyy-dd-mm format\n",
    "reg_date2= re.compile(r\"(\\d{2})-(\\d{2})-(\\d{4})\") #it matches the date in dd-mm-yyyy format\n",
    "\n",
    "#performing iterations on every row to check the date format \n",
    "for n,j in dirty_data.iterrows():\n",
    "    hold_date=j['date']                            #storinf the date for each row into variable named hold_date\n",
    "    date1=re.findall(reg_date1,hold_date)          #performing regex using reg_date1 to extract the date of format yyyy-mm-dd or yyyy-dd-mm\n",
    "    if len(date1) == 0:                            #if nothing extracted, that means the date is of the format dd-mm-yyyy\n",
    "        date2=re.findall(reg_date2,hold_date)[0]   #performing another regex to extract the list of data of three groups (day,month,year) induvidually\n",
    "        #ectracted data is used to reverse the order and print date in correct format using string concatination\n",
    "        dirty_data.iloc[n,1] = date2[2]+'-'+date2[1]+'-'+date2[0]\n",
    "        \n",
    "    else:                                          #else something is extracted of the form yyyy-mm-dd or yyyy-dd-mm\n",
    "        #if the value of the second group is greater than 12, then, its the date as the month count can never be greater than 12\n",
    "        if int(date1[0][1])>12:\n",
    "            #interchange the 2nd and 3rd group value for resulting format to be yyyy-mm-dd\n",
    "            dirty_data.iloc[n,1] = date1[0][0]+'-'+date1[0][2]+'-'+date1[0][1]\n",
    "    #otherwise the date is already in the correct format tthat is yyyy-mm-dd.\n",
    "            \n",
    "#the dates have been fixed now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the correct order_type with respect to the time given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>14:35:29</td>\n",
       "      <td>Breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>17:58:18</td>\n",
       "      <td>Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>11:43:05</td>\n",
       "      <td>Breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>08:50:42</td>\n",
       "      <td>Breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>17:58:18</td>\n",
       "      <td>Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>16:57:27</td>\n",
       "      <td>Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>15:26:11</td>\n",
       "      <td>Breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>16:16:54</td>\n",
       "      <td>Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>10:21:58</td>\n",
       "      <td>Breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>16:57:27</td>\n",
       "      <td>Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>12:54:05</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>12:23:39</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>16:06:45</td>\n",
       "      <td>Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>10:52:23</td>\n",
       "      <td>Breakfast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time order_type\n",
       "486  14:35:29  Breakfast\n",
       "487  17:58:18     Dinner\n",
       "488  11:43:05  Breakfast\n",
       "489  08:50:42  Breakfast\n",
       "490  17:58:18     Dinner\n",
       "491  16:57:27     Dinner\n",
       "492  15:26:11  Breakfast\n",
       "493  16:16:54     Dinner\n",
       "494  10:21:58  Breakfast\n",
       "495  16:57:27     Dinner\n",
       "496  12:54:05      Lunch\n",
       "497  12:23:39      Lunch\n",
       "498  16:06:45     Dinner\n",
       "499  10:52:23  Breakfast"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data[['time','order_type']].tail(14) #seeing the last 14 values of columns 'time' and 'order_type' using .tail(14) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are provide with the following information \n",
    "\n",
    "There are three types of meals:\n",
    "* Breakfast - served during morning (8am - 12pm),\n",
    "* Lunch - served during afternoon (12:00:01pm - 4pm)\n",
    "* Dinner - served during evening (4:00:01pm - 8pm)\n",
    "\n",
    "Check the row 486 and 492. The time of the order doesn't correspond to the order type. The order_type is breakfast instead of lunch. Therefore the order_type needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterrows() function will loop through each row of a dataframe\n",
    "\n",
    "for n,j in dirty_data.iterrows():\n",
    "    time = j['time']        #saving each value of'time' in time\n",
    "    order = j['order_type'] #saving each value of 'order_type' in order\n",
    "    \n",
    "    \n",
    "    #if the time is in between 8am to 12pm and order_type is not equal to Breakfast then use iloc to loacte the error and fix it by assigning 'Breakfast' to it.\n",
    "    #.iloc[n,3] the datavalue with n as the index of the row and 3 means the column 'order_type'\n",
    "    if (time >= '08:00:00') & (time <= '12:00:00') & (order != 'Breakfast'):\n",
    "        dirty_data.iloc[n,3] = 'Breakfast' \n",
    "        \n",
    "    \n",
    "    #if the time is in between 12:01pm to 4pm and order_type is not equal to Lunch then use iloc to loacte the error and fix it by assigning 'Lunch' to it.\n",
    "    if (time > '12:00:00') & (time <= '16:00:00') & (order != 'Lunch'):\n",
    "        dirty_data.iloc[n,3] = 'Lunch'\n",
    "        \n",
    "        \n",
    "    #if the time is in between 4:01pm to 8pm and order_type is not equal to Dinner then use iloc to loacte the error and fix it by assigning 'Dinner' to it.\n",
    "    if (time > '16:00:00') & (time <= '20:00:00') & (order != 'Dinner'):\n",
    "        dirty_data.iloc[n,3] = 'Dinner'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the errors in customer_lat and cutomer_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean     -30.753763\n",
       "std       25.336331\n",
       "min      -37.828216\n",
       "25%      -37.817794\n",
       "50%      -37.811639\n",
       "75%      -37.804107\n",
       "max      144.976883\n",
       "Name: customer_lat, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.customer_lat.describe() #.describe() tells the distribution(statisitcs) of customer_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean     143.503721\n",
       "std       16.298857\n",
       "min      -37.819026\n",
       "25%      144.950582\n",
       "50%      144.963488\n",
       "75%      144.978716\n",
       "max      145.016633\n",
       "Name: customer_lon, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.customer_lon.describe() #.describe() tells the distribution(statisitcs) of customer_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latitude angles range from -90$^\\circ$ to 90$^\\circ$\n",
    "\n",
    "The longitude angles range from 0$^\\circ$ to 180$^\\circ$\n",
    "\n",
    "On visualizing the descriptive stasitics of customer_lat of the data given, we can observe that maximum value is 144.97 which is definately wrong entry as it should be in range from -90 to 90. Similalry, the minimum value of descriptive statisitcs of customer_lon is -37.81 which is a similar error as above, out of range. \n",
    "\n",
    "Now we check the rows where customer_lat is not in the range(-90 to 90) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ORDC07297</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>12:43:56</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Chicken', 4), ('Salad', 9), ('Burger', 4), ...</td>\n",
       "      <td>760.8</td>\n",
       "      <td>144.976883</td>\n",
       "      <td>-37.819026</td>\n",
       "      <td>0</td>\n",
       "      <td>8.462</td>\n",
       "      <td>13.607341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ORDC00656</td>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>15:05:54</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Burger', 2), ('Fries', 6)]</td>\n",
       "      <td>134.0</td>\n",
       "      <td>144.965627</td>\n",
       "      <td>-37.812000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.662</td>\n",
       "      <td>13.471045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>ORDZ03764</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>14:15:12</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Chicken', 3), ('Burger', 10), ('Steak', 10)...</td>\n",
       "      <td>993.2</td>\n",
       "      <td>144.942916</td>\n",
       "      <td>-37.805785</td>\n",
       "      <td>0</td>\n",
       "      <td>9.165</td>\n",
       "      <td>14.381864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>ORDY04585</td>\n",
       "      <td>2018-08-23</td>\n",
       "      <td>15:46:28</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Chicken', 7), ('Burger', 6), ('Fries', 1), ...</td>\n",
       "      <td>737.0</td>\n",
       "      <td>144.937511</td>\n",
       "      <td>-37.806875</td>\n",
       "      <td>0</td>\n",
       "      <td>10.488</td>\n",
       "      <td>13.212223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id        date      time order_type branch_code  \\\n",
       "208  ORDC07297  2018-05-24  12:43:56      Lunch          NS   \n",
       "291  ORDC00656  2018-08-06  15:05:54      Lunch          NS   \n",
       "313  ORDZ03764  2018-07-11  14:15:12      Lunch          NS   \n",
       "454  ORDY04585  2018-08-23  15:46:28      Lunch          TP   \n",
       "\n",
       "                                           order_items  order_price  \\\n",
       "208  [('Chicken', 4), ('Salad', 9), ('Burger', 4), ...        760.8   \n",
       "291                      [('Burger', 2), ('Fries', 6)]        134.0   \n",
       "313  [('Chicken', 3), ('Burger', 10), ('Steak', 10)...        993.2   \n",
       "454  [('Chicken', 7), ('Burger', 6), ('Fries', 1), ...        737.0   \n",
       "\n",
       "     customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "208    144.976883    -37.819026                    0                    8.462   \n",
       "291    144.965627    -37.812000                    0                    7.662   \n",
       "313    144.942916    -37.805785                    0                    9.165   \n",
       "454    144.937511    -37.806875                    0                   10.488   \n",
       "\n",
       "     delivery_fee  \n",
       "208     13.607341  \n",
       "291     13.471045  \n",
       "313     14.381864  \n",
       "454     13.212223  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data[(dirty_data['customer_lat'] > 90) | (dirty_data['customer_lat'] < -90)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 rows where customer_lat is out of range and infact we can also observe that the values in customer_lat and customer_lot are swapped. In the next step we are going to rectify these 4 rows by swapping their respective values from customer_lat to customer_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterrows() function will loop through each row of a dataframe\n",
    "\n",
    "for a,b in dirty_data.iterrows():\n",
    "    lat = b['customer_lat'] #saving each value of'customer_lat' in lat\n",
    "            \n",
    "    #if the lat is greater than 90 i.e out of range\n",
    "    # we swap the values of customer_lat and customer_long\n",
    "    if lat >= 90:\n",
    "        temp = dirty_data.iloc[a,7]  #storing the value of customer_lat in temp\n",
    "        dirty_data.iloc[a,7]= dirty_data.iloc[a,8] #assigning the value of customer_lon to customer_lat \n",
    "        dirty_data.iloc[a,8]= temp #assigning the value of temp(customer_lat) to customer_lon\n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above errors are fixed. We are provided with the nodes_data which provides the information regarding the node w.r.t latitude and longitude. So just to keep a check, we observed that latitude doesn't have any values greater than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [node, lat, lon]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_data = pd.read_csv(\"nodes.csv\")\n",
    "nodes_data[nodes_data['lat'] > 0] # there are 0 values of lat with any postive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                   37\n",
       "date                       37\n",
       "time                       37\n",
       "order_type                 37\n",
       "branch_code                37\n",
       "order_items                37\n",
       "order_price                37\n",
       "customer_lat               37\n",
       "customer_lon               37\n",
       "customerHasloyalty?        37\n",
       "distance_to_customer_KM    37\n",
       "delivery_fee               37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data[dirty_data['customer_lat'] > 0].count()  # 37 values of latitude are positve which needs to fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterrows() function will loop through each row of a dataframe\n",
    "for a,b in dirty_data.iterrows():\n",
    "    lat = b['customer_lat'] #saving each value of'customer_lat' in lat\n",
    "    \n",
    "    #if the lat is greater than 0 then multiplying it by -1 to make it negative.\n",
    "    if (lat >=0):\n",
    "        dirty_data.iloc[a,7] = dirty_data.iloc[a,7] * (-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the errors in distance_to_customer_KM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load the data using Pandas library and store them in the respective dataframes by \"pd.read_csv()\"\n",
    "#these datastes provide the correct information about the locations.\n",
    " \n",
    "nodes_data = pd.read_csv(\"nodes.csv\") \n",
    "edges_data = pd.read_csv(\"edges.csv\")\n",
    "branches_data = pd.read_csv(\"branches.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to merge the dataframes and we do it by using merge. \"pd.merge\" merges two DataFrames or named Series objects with a database-style join. We first perform a left join on dirty_data and nodes_data so that to corresponding customer lat and lon we get the correct customer nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'how' - left outer join on dirty_data and nodes_data \n",
    "# right_on -Columns to join on in the right DataFrame. \n",
    "# left_on - Columns to join on in the left DataFrame. \n",
    "\n",
    "dirty_data = pd.merge(left=dirty_data,right=nodes_data, how='left', left_on=['customer_lat','customer_lon'], right_on=['lat','lon'])\n",
    "#we are merging on the same dataframe\n",
    "\n",
    "dirty_data=dirty_data.drop(columns=['lat','lon'])\n",
    "dirty_data=dirty_data.rename(columns={'node':'customer_node'})\n",
    "\n",
    "#after joing, dropping the columns lat and lon and renaming the column 'node' to 'customer_node' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform left join on branches_data and nodes_data so that to corresponding branch lat and lon we get the correct branch nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_code</th>\n",
       "      <th>branch_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NS</td>\n",
       "      <td>2455254505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "      <td>1390575046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BK</td>\n",
       "      <td>1889485053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_code  branch_node\n",
       "0          NS   2455254505\n",
       "1          TP   1390575046\n",
       "2          BK   1889485053"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'how' - left outer join on dirty_data and nodes_data \n",
    "# right_on -Columns to join on in the right DataFrame. \n",
    "# left_on - Columns to join on in the left DataFrame\n",
    "\n",
    "branches1= pd.merge(left=branches_data,right=nodes_data, how='left', left_on=['branch_lat','branch_lon'], right_on=['lat','lon'])\n",
    "#creating a new datframe branches1 and then merging.\n",
    "\n",
    "branches1=branches1.drop(columns=['lon','lat','branch_lat','branch_lon','branch_name'])\n",
    "branches1=branches1.rename(columns={'node':'branch_node'})\n",
    "\n",
    "\n",
    "#after joing, dropping the columns lon, lat, branch_lat, branch_lon and branch_name and renaming the column 'node' to 'branch_node'\n",
    "branches1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to perform left join on branches1 and dirty_data so that to to corresponding branch code we get correct branch node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>customer_node</th>\n",
       "      <th>branch_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORDJ07617</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>15:36:20</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Chicken', 6), ('Steak', 5), ('Burger', 9), ...</td>\n",
       "      <td>730.4</td>\n",
       "      <td>-37.818790</td>\n",
       "      <td>144.955280</td>\n",
       "      <td>0</td>\n",
       "      <td>8.299</td>\n",
       "      <td>11.938508</td>\n",
       "      <td>2247180690</td>\n",
       "      <td>1390575046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORDY05853</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>13:44:47</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Eggs', 8), ('Chicken', 9), ('Burger', 4), (...</td>\n",
       "      <td>656.2</td>\n",
       "      <td>-37.824714</td>\n",
       "      <td>144.984714</td>\n",
       "      <td>0</td>\n",
       "      <td>8.921</td>\n",
       "      <td>12.535316</td>\n",
       "      <td>746912608</td>\n",
       "      <td>1390575046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id        date      time order_type branch_code  \\\n",
       "0  ORDJ07617  2018-08-17  15:36:20      Lunch          TP   \n",
       "1  ORDY05853  2018-06-26  13:44:47      Lunch          TP   \n",
       "\n",
       "                                         order_items  order_price  \\\n",
       "0  [('Chicken', 6), ('Steak', 5), ('Burger', 9), ...        730.4   \n",
       "1  [('Eggs', 8), ('Chicken', 9), ('Burger', 4), (...        656.2   \n",
       "\n",
       "   customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "0    -37.818790    144.955280                    0                    8.299   \n",
       "1    -37.824714    144.984714                    0                    8.921   \n",
       "\n",
       "   delivery_fee  customer_node  branch_node  \n",
       "0     11.938508     2247180690   1390575046  \n",
       "1     12.535316      746912608   1390575046  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'how' - left outer join on dirty_data and nodes_data \n",
    "# right_on -Columns to join on in the right DataFrame. \n",
    "# left_on - Columns to join on in the left DataFrame\n",
    "\n",
    "dirty_data=pd.merge(left=dirty_data,right=branches1, how='left', left_on=['branch_code'], right_on=['branch_code'])\n",
    "dirty_data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have branch code and customer node and now we can find out the shortest distance in km with the help of <b>Dijkstra Algorithim</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in the graph are  17117\n"
     ]
    }
   ],
   "source": [
    "import networkx\n",
    "G = networkx.Graph() #Creating an empty graph with no nodes and no edges.\n",
    "n=nodes_data.node    # storing nodes in n from the nodes_data\n",
    "G.add_nodes_from(n)  # Adding the nodes 'n' to G\n",
    "print('The number of nodes in the graph are ',G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of edges in the graph are  25491\n"
     ]
    }
   ],
   "source": [
    "\n",
    "u=edges_data['u']                  #storing 'u' in u from the edges_data\n",
    "v=edges_data['v']                  #storing 'v' in v from the edges_data\n",
    "distance=edges_data['distance(m)'] #storing 'distacne(m)' in distance from the edges_data\n",
    "\n",
    "temp_list=list(zip(u,v,distance)) #zipping all the above variables and storing them in list. \n",
    "\n",
    "G.add_weighted_edges_from(temp_list) # addding the edges to G from the temp_list\n",
    "print('The number of edges in the graph are ',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pt=dirty_data['branch_node']  #storing each 'branch_code' in initial_pt from the dirty_data\n",
    "final_pt=dirty_data['customer_node']  #storing each 'customer_code' in final_pt from the dirty_data\n",
    "\n",
    "temp_list1=list(zip(initial_pt,final_pt)) #zipping the variables and storing them in list\n",
    "dis=[] #empty list\n",
    "\n",
    "for a,b in temp_list1:\n",
    "    dis.append(networkx.dijkstra_path_length(G,a,b))\n",
    "    #dijkstra_path_length returns the shortest path length from source to target in a weighted graph.\n",
    "    #appending all the distances to the list dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The distance we calculated is in metres and we need to convert it into km since the distance_to_customer_KM is given in kms.\n",
    "#we divide each item of the list by 1000 using for loop and appending the new items into new list 'correct_dis'\n",
    "correct_dis=[] \n",
    "for x in dis:\n",
    "    correct_dis.append(x/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding another column 'correct_dis_km' to the dataframe which have the values we found above.\n",
    "dirty_data['correct_dis_km']=correct_dis\n",
    "\n",
    "# iterrows() function will loop through each row of a dataframe\n",
    "for a,b in dirty_data.iterrows():\n",
    "    \n",
    "    actual = b['correct_dis_km'] #saving each data value of correct_dis_km to actual\n",
    "    given = round(b['distance_to_customer_KM'],3) #saving rounding value upto 3 decimals of each data value of \n",
    "                                                  #'distance_to_customer_KM' to given\n",
    "    \n",
    "    #if given is not equal to actual then fixing it by assigning the correct value.\n",
    "    if given != actual:\n",
    "        dirty_data.iloc[a,10]= dirty_data.iloc[a,14] #assigning the correct value to the places where there is an error\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menu check\n",
    "We need to check if people have ordered from the right menu or not. There may be some error in order_items. There are some rows with order_items from different time menu. For that, we need to calculate the correct menu from outlier data file first. We will create three lists for menu of each time, i.e. breakfast, lunch, dinner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fish&Chips', 'Pasta', 'Salmon', 'Shrimp']\n",
      "['Pancake', 'Cereal', 'Coffee', 'Eggs']\n",
      "['Steak', 'Salad', 'Chicken', 'Burger', 'Fries']\n"
     ]
    }
   ],
   "source": [
    "#first we will create three empty list for storing menu items in each list for breakfast, lunch and dinner.\n",
    "breakfast=[]\n",
    "lunch=[]\n",
    "dinner=[]\n",
    "for a,b in outlier_data.iterrows():        #performing iteration on all rows of the data\n",
    "    food = b['order_items']                #storing all the ordered itmes (string type) in variable named 'food'\n",
    "    o_type = b['order_type']               #storing the type of order (if food is breakfast, lunch or dinner)in o_type variable\n",
    "    \n",
    "    if o_type == 'Breakfast':              #if food type is breakfast then store the order items in list named breakfast   \n",
    "        breakfast.append(food)\n",
    "    \n",
    "    if o_type == 'Lunch':                  #if food type is lunch then store the order items in list named lunch\n",
    "        lunch.append(food)\n",
    "    \n",
    "    if o_type == 'Dinner':                 #if food type is dinner then store the order items in list named dinner\n",
    "        dinner.append(food) \n",
    "        \n",
    "reg_order= re.compile(\"\\('(.*?)',\")        #defining a regex to extract the item names from the string of items and quantity.\n",
    "\n",
    "#coverted the list of all items of dinner into string to perform regex and \n",
    "#extracting all the matches for items using regex defined above\n",
    "dinner_menu=re.findall(reg_order,str(dinner))\n",
    "dinner_menu=list(set(dinner_menu))         #convert list or items extracted above to set to get unique list of items\n",
    "print(dinner_menu)\n",
    "\n",
    "#coverted the list of all items of breakfast into string to perform regex and \n",
    "#extracting all the matches for items using regex defined above\n",
    "breakfast_menu=re.findall(reg_order,str(breakfast))   \n",
    "breakfast_menu=list(set(breakfast_menu))    #convert list or items extracted above to set to get unique list of items\n",
    "print(breakfast_menu)\n",
    "\n",
    "#coverted the list of all items of lunch into string to perform regex and \n",
    "#extracting all the matches for items using regex defined above\n",
    "lunch_menu=re.findall(reg_order,str(lunch))\n",
    "lunch_menu=list(set(lunch_menu))      #convert list or items extracted above to set to get unique list of items\n",
    "print(lunch_menu)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>customer_node</th>\n",
       "      <th>branch_node</th>\n",
       "      <th>correct_dis_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORDJ07617</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>15:36:20</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Chicken', 6), ('Steak', 5), ('Burger', 9), ...</td>\n",
       "      <td>730.40</td>\n",
       "      <td>-37.818790</td>\n",
       "      <td>144.955280</td>\n",
       "      <td>0</td>\n",
       "      <td>8.299</td>\n",
       "      <td>11.938508</td>\n",
       "      <td>2247180690</td>\n",
       "      <td>1390575046</td>\n",
       "      <td>8.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORDY05853</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>13:44:47</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Eggs', 8), ('Chicken', 9), ('Burger', 4), (...</td>\n",
       "      <td>656.20</td>\n",
       "      <td>-37.824714</td>\n",
       "      <td>144.984714</td>\n",
       "      <td>0</td>\n",
       "      <td>8.921</td>\n",
       "      <td>12.535316</td>\n",
       "      <td>746912608</td>\n",
       "      <td>1390575046</td>\n",
       "      <td>8.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORDI02968</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>08:50:42</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Coffee', 4), ('Pancake', 7), ('Eggs', 4)]</td>\n",
       "      <td>287.75</td>\n",
       "      <td>-37.824977</td>\n",
       "      <td>144.988823</td>\n",
       "      <td>0</td>\n",
       "      <td>9.692</td>\n",
       "      <td>14.390854</td>\n",
       "      <td>266740437</td>\n",
       "      <td>2455254505</td>\n",
       "      <td>9.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORDY06446</td>\n",
       "      <td>2018-06-24</td>\n",
       "      <td>13:44:47</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Steak', 2), ('Chicken', 9), ('Salad', 10)]</td>\n",
       "      <td>550.00</td>\n",
       "      <td>-37.818858</td>\n",
       "      <td>144.974113</td>\n",
       "      <td>0</td>\n",
       "      <td>8.197</td>\n",
       "      <td>13.361016</td>\n",
       "      <td>579402454</td>\n",
       "      <td>1390575046</td>\n",
       "      <td>8.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORDZ01045</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>17:07:36</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pasta', 1), ('Fish&amp;Chips', 9), ('Salmon', 8...</td>\n",
       "      <td>778.50</td>\n",
       "      <td>-37.812362</td>\n",
       "      <td>144.973720</td>\n",
       "      <td>0</td>\n",
       "      <td>7.576</td>\n",
       "      <td>13.731754</td>\n",
       "      <td>589398474</td>\n",
       "      <td>2455254505</td>\n",
       "      <td>7.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORDA06887</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>10:11:49</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Pancake', 3), ('Eggs', 10), ('Coffee', 2), ...</td>\n",
       "      <td>412.75</td>\n",
       "      <td>-37.803644</td>\n",
       "      <td>144.963391</td>\n",
       "      <td>0</td>\n",
       "      <td>7.674</td>\n",
       "      <td>14.703081</td>\n",
       "      <td>1492410194</td>\n",
       "      <td>1889485053</td>\n",
       "      <td>7.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORDB08630</td>\n",
       "      <td>2018-11-26</td>\n",
       "      <td>18:49:00</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Fish&amp;Chips', 9), ('Eggs', 1), ('Shrimp', 7)...</td>\n",
       "      <td>954.00</td>\n",
       "      <td>-37.806155</td>\n",
       "      <td>144.958304</td>\n",
       "      <td>0</td>\n",
       "      <td>9.074</td>\n",
       "      <td>12.801646</td>\n",
       "      <td>777768981</td>\n",
       "      <td>1390575046</td>\n",
       "      <td>9.074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id        date      time order_type branch_code  \\\n",
       "0  ORDJ07617  2018-08-17  15:36:20      Lunch          TP   \n",
       "1  ORDY05853  2018-06-26  13:44:47      Lunch          TP   \n",
       "2  ORDI02968  2018-01-26  08:50:42  Breakfast          NS   \n",
       "3  ORDY06446  2018-06-24  13:44:47      Lunch          TP   \n",
       "4  ORDZ01045  2018-10-02  17:07:36     Dinner          NS   \n",
       "5  ORDA06887  2018-03-11  10:11:49  Breakfast          BK   \n",
       "6  ORDB08630  2018-11-26  18:49:00     Dinner          TP   \n",
       "\n",
       "                                         order_items  order_price  \\\n",
       "0  [('Chicken', 6), ('Steak', 5), ('Burger', 9), ...       730.40   \n",
       "1  [('Eggs', 8), ('Chicken', 9), ('Burger', 4), (...       656.20   \n",
       "2       [('Coffee', 4), ('Pancake', 7), ('Eggs', 4)]       287.75   \n",
       "3      [('Steak', 2), ('Chicken', 9), ('Salad', 10)]       550.00   \n",
       "4  [('Pasta', 1), ('Fish&Chips', 9), ('Salmon', 8...       778.50   \n",
       "5  [('Pancake', 3), ('Eggs', 10), ('Coffee', 2), ...       412.75   \n",
       "6  [('Fish&Chips', 9), ('Eggs', 1), ('Shrimp', 7)...       954.00   \n",
       "\n",
       "   customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "0    -37.818790    144.955280                    0                    8.299   \n",
       "1    -37.824714    144.984714                    0                    8.921   \n",
       "2    -37.824977    144.988823                    0                    9.692   \n",
       "3    -37.818858    144.974113                    0                    8.197   \n",
       "4    -37.812362    144.973720                    0                    7.576   \n",
       "5    -37.803644    144.963391                    0                    7.674   \n",
       "6    -37.806155    144.958304                    0                    9.074   \n",
       "\n",
       "   delivery_fee  customer_node  branch_node  correct_dis_km  \n",
       "0     11.938508     2247180690   1390575046           8.299  \n",
       "1     12.535316      746912608   1390575046           8.921  \n",
       "2     14.390854      266740437   2455254505           9.692  \n",
       "3     13.361016      579402454   1390575046           8.197  \n",
       "4     13.731754      589398474   2455254505           7.576  \n",
       "5     14.703081     1492410194   1889485053           7.674  \n",
       "6     12.801646      777768981   1390575046           9.074  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.head(7) # row 1 and 6 has order_type lunch and dinner respectively  while its order_item have eggs in it which is an item of breakfast menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,j in dirty_data.iterrows():       #iteration on rows of dataframe \n",
    "    order_t=j['order_type']             #storing the order type in variable named order_t to check if the food is breakfast, lunch or dinner\n",
    "    menu=j['order_items']               #storing the string of items ordered in menu variable\n",
    "    if order_t=='Breakfast':            #check if order type is breakfast then compare the order items from breakfast menu\n",
    "        time_menu=breakfast_menu\n",
    "    if order_t=='Lunch':                #check if order type is lunch then compare the order items from lunch menu\n",
    "        time_menu=lunch_menu\n",
    "    if order_t=='Dinner':               #check if order type is dinner then compare the order items from dinner menu\n",
    "        time_menu=dinner_menu\n",
    "    \n",
    "#we need to conert the string of order items into a list of items to compare from the menue and the remove the items which are not in the menue\n",
    "#for this we firts striped the string and then replaces some parts with '|' to use this as delimeter to split the string into list\n",
    "    a=menu.strip('([])').replace('), (','|').split('|')\n",
    "    b=[]               #defining an empty list to store the items which are in the menue\n",
    "    for x in a:\n",
    "        if re.findall(\"'(.*?)'\",x)[0] in time_menu:          #using regex, check if each item extracted is in the menue \n",
    "            b.append(x)                                      #if present in the menu, add element to list 'b' \n",
    "        dirty_data.iloc[n,5]= '[('+'),('.join(b)+')]'        #imputing the list of elements in the form of string the previous pattern into the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the outlier data we used order_items in order to solve the linear equations.\n",
    " \n",
    " * 4 order_items in from of equations for breakfast\n",
    " * 5 order_items in form of equatiions for lunch\n",
    " * 4 order_items in form of equations for dinner\n",
    " \n",
    " We use np.linalg.solve(a,b) which solves a linear matrix equation\n",
    " * a is coefficient matrix\n",
    " * b is the matrix with price\n",
    " \n",
    " It returns the unit prices for each order_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price for fries, burger, steak, salad ,chicken [12.  31.  45.  17.2 32. ]\n",
      "price for shrimp, fish&chips, pasta ,Salmon [54.  35.  27.5 41. ]\n",
      "price for pancakes, eggs, coffee , cereall [24.25 22.    7.5  21.  ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "coff_br=np.array([[10, 8, 5, 9],[5, 4, 6, 3],[6, 4, 9, 3],[4, 5, 8, 7]])\n",
    "coff_dr=np.array([[6, 5, 6, 5],[5, 9, 9, 2],[9, 2, 10, 7],[7, 2, 7, 9]])\n",
    "coff_lu=np.array([[6, 7, 4, 10, 4],[4, 2, 5, 7, 7],[10, 9, 1, 2, 8],[6, 10, 4, 7, 9],[6, 7, 8, 5, 9]])\n",
    "\n",
    "dep_br=np.array([645.0,317.25,364.0,414.0])\n",
    "dep_dr=np.array([869.0,914.5,1118.0,1009.5])\n",
    "dep_lu=np.array([769.0,679.4,734.4,970.4,1023.0])\n",
    "\n",
    "\n",
    "break_pr=np.linalg.solve(coff_br,dep_br)\n",
    "din_pr=np.linalg.solve(coff_dr,dep_dr)\n",
    "lun_pr=np.linalg.solve(coff_lu,dep_lu)\n",
    "\n",
    "print('price for fries, burger, steak, salad ,chicken',lun_pr)\n",
    "print('price for shrimp, fish&chips, pasta ,Salmon',din_pr)\n",
    "print('price for pancakes, eggs, coffee , cereall',break_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the price of each item of all the three food type menu. we will now use this price rate to calculate the total bill for every customer order. Also, if the customer has loyalty equal to one, the customer will gwt 50% discount on his/her shopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining three list for each food type to store the list of quantity of each items for every food type induvidually.\n",
    "br = []\n",
    "lu = []\n",
    "dr = []\n",
    "for n,j in dirty_data.iterrows():            #iteration through rows of dataframe\n",
    "    price = j['order_price']                 #for every row store the price into the variable named price\n",
    "    items = j['order_items']                 #for every row store the items ordered by the customer into the variable named items\n",
    "    ord_t = j['order_type']                  #for every row store the food type into the variable named ord_t to check the right menu for comparison\n",
    "\n",
    "#now, we will calculate the list of elements contating list of quantity of each item for every food type\n",
    "    if ord_t=='Lunch':                 \n",
    "    #if food is Lunch store the quantity of fries, burger, steak, salad and chicken in variable a,b,c,d and e respectively\n",
    "    #using the regex which will extract the digit followed by the item name\n",
    "        a = ''.join(re.findall(\"Fries', (\\d+)\",items))\n",
    "        b = ''.join(re.findall(\"Burger', (\\d+)\",items))\n",
    "        c = ''.join(re.findall(\"Steak', (\\d+)\",items))\n",
    "        d = ''.join(re.findall(\"Salad', (\\d+)\",items))\n",
    "        e = ''.join(re.findall(\"Chicken', (\\d+)\",items))\n",
    "        \n",
    "        #if any item is not ordered, i.e is not present in the order_item string, then assign 0 as the quantity\n",
    "        if a == '':\n",
    "            a=0\n",
    "        if b == '':\n",
    "            b=0\n",
    "        if c == '':\n",
    "            c=0\n",
    "        if d == '':\n",
    "            d=0\n",
    "        if e == '':\n",
    "            e=0\n",
    "        #append the list of values into the main list for lunch in the form of integer\n",
    "        lu.append([int(a),int(b),int(c),int(d),int(e)])\n",
    "        \n",
    "    if ord_t=='Breakfast':\n",
    "    #if food is Breakfast store the quantity of pancakes, eggs, coffee and cereal in variable a,b,c and d respectively\n",
    "    #using the regex which will extract the digit followed by the item name\n",
    "        a = ''.join(re.findall(\"Pancake', (\\d+)\",items))\n",
    "        b = ''.join(re.findall(\"Eggs', (\\d+)\",items))\n",
    "        c = ''.join(re.findall(\"Coffee', (\\d+)\",items))\n",
    "        d = ''.join(re.findall(\"Cereal', (\\d+)\",items))\n",
    "        \n",
    "        #if any item is not ordered, i.e is not present in the order_item string, then assign 0 as the quantity\n",
    "        if a == '':\n",
    "            a=0\n",
    "        if b == '':\n",
    "            b=0\n",
    "        if c == '':\n",
    "            c=0\n",
    "        if d == '':\n",
    "            d=0\n",
    "        #append the list of values into the main list for breakfast in the form of integer\n",
    "        br.append([int(a),int(b),int(c),int(d)])\n",
    "        \n",
    "    if ord_t=='Dinner':\n",
    "    #if food is dinner store the quantity of shrimp, fish&chips, pasta and Salmon in variable a,b,c and d respectively\n",
    "    #using the regex which will extract the digit followed by the item name\n",
    "        a = ''.join(re.findall(\"Shrimp', (\\d+)\",items))\n",
    "        b = ''.join(re.findall(\"Fish&Chips', (\\d+)\",items))\n",
    "        c = ''.join(re.findall(\"Pasta', (\\d+)\",items))\n",
    "        d = ''.join(re.findall(\"Salmon', (\\d+)\",items))\n",
    "        \n",
    "        #if any item is not ordered, i.e is not present in the order_item string, then assign 0 as the quantity\n",
    "        if a == '':\n",
    "            a=0\n",
    "        if b == '':\n",
    "            b=0\n",
    "        if c == '':\n",
    "            c=0\n",
    "        if d == '':\n",
    "            d=0\n",
    "        #append the list of values into the main list for breakfast in the form of integer\n",
    "        dr.append([int(a),int(b),int(c),int(d)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the list of quantity of all the the items for every food type which can be used to check the price of ordered food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,m,o = 0,0,0\n",
    "#define three flags named l,m and o\n",
    "for n,j in dirty_data.iterrows(): \n",
    "    #for every row save the order price into price variable and type of order into o_t variable\n",
    "    price = j['order_price']\n",
    "    o_t = j['order_type']\n",
    "    if o_t == 'Breakfast':\n",
    "    #if the type is breakfast, take the first element of the list created above and perform dot product with the list of actual price of the items to get the total price of the data\n",
    "        dirty_data.iloc[n,6]=round(np.dot(br[l],break_pr),2)  \n",
    "        #make an increment in the flag to get to the next value for next occurence of breakfast type food\n",
    "        l+=1\n",
    "            \n",
    "    if o_t == 'Lunch':\n",
    "    #if the type is lunch, take the first element of the list created above and perform dot product with the list of actual price of the items to get the total price of the data\n",
    "        dirty_data.iloc[n,6]=round(np.dot(lu[m],lun_pr),2) \n",
    "        #make an increment in the flag to get to the next value for next occurence of lunch type food\n",
    "        m+=1\n",
    "        \n",
    "    if o_t == 'Dinner':\n",
    "    #if the type is dinner, take the first element of the list created above and perform dot product with the list of actual price of the items to get the total price of the data\n",
    "        dirty_data.iloc[n,6]=round(np.dot(dr[o],din_pr),2)\n",
    "        #make an increment in the flag to get to the next value for next occurence of dinner type food\n",
    "        o+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the errors with loyalty \n",
    "\n",
    "The approach to fix the loayalty will be to check the delivery fee. The delivery fee depends linearly on 3 variables, time of the day, day of the week and the distance from the customer. We will build a linear model to predict the delivery fee.\n",
    "\n",
    "Since the missing_data_mod has no errors so we can build(train and test) our model on it and then predict the values for delivery fee on the dirty_data and then check the loyalty according to it.\n",
    "\n",
    "Before starting we need to add 2 new columns in both the files, dirty_data and missing_data_mod. \n",
    "\n",
    "* Column 'time_of_day' tells us the time when the food was ordered (morning 0, afternoon 1, evening 2)\n",
    "* Column 'weekend_weekday' tells us whether the food was oredered on weekend or weekday (1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to dirty_data with all values assigned to 0.\n",
    "dirty_data['time_of_day']=[0]*dirty_data.shape[0]\n",
    "\n",
    "\n",
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "\n",
    "for a,b in dirty_data.iterrows():\n",
    "    meal=b['order_type'] #saving each order_type in meal\n",
    "    \n",
    "    \n",
    "    #if meal is equal to Breakfast then assinging value 0 to the column 'time_of_day'\n",
    "    if meal=='Breakfast':\n",
    "        dirty_data.iloc[a,15]=0 #iloc[a,15] is datavalue with a as the index of the row and 15 means the column 'time_of_day'\n",
    "    \n",
    "    \n",
    "    #if meal is equal to Lunch then assinging value 1 to the column 'time_of_day'   \n",
    "    if meal=='Lunch':\n",
    "        dirty_data.iloc[a,15]=1\n",
    "        \n",
    "        \n",
    "    #if meal is equal to Dinner then assinging value 2 to the column 'time_of_day'    \n",
    "    if meal =='Dinner':\n",
    "        dirty_data.iloc[a,15]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to dirty_data with all values assigned to 0\n",
    "dirty_data['weekend_weekday']=[0]*dirty_data.shape[0]\n",
    "\n",
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "\n",
    "for a,b in dirty_data.iterrows():\n",
    "    date=b['date'] #saving each date in meal\n",
    "    \n",
    "    # Timestamp is the pandas equivalent to pythons Datetime\n",
    "    # Its used for converting the entries into dates that make up a DatetimeIndex in pandas.\n",
    "    # df.dayofweek returns the day of week. Monday is treated as 0 and Sunday is treated as 6.\n",
    "    df = pd.Timestamp(date)\n",
    "    day=df.dayofweek\n",
    "    \n",
    "    #if it is a weekday( 0,1,2,3,4) then assigning the value 0 to the column 'weekend_weekday'\n",
    "    if (day==0) or (day==1) or (day==1) or (day==2) or (day==3) or (day==4):\n",
    "        dirty_data.iloc[a,16]=0\n",
    "        \n",
    "    #if it is a weekend(5,6) then assigning the value 1 to the column 'weekend_weekday'    \n",
    "    if (day==5) or (day==6):\n",
    "        dirty_data.iloc[a,16]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the Group154_missing_data once again into missing_data_mod using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_mod=pd.read_csv(\"Group154_missing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      "order_id                   500 non-null object\n",
      "date                       500 non-null object\n",
      "time                       500 non-null object\n",
      "order_type                 500 non-null object\n",
      "branch_code                400 non-null object\n",
      "order_items                500 non-null object\n",
      "order_price                500 non-null float64\n",
      "customer_lat               500 non-null float64\n",
      "customer_lon               500 non-null float64\n",
      "customerHasloyalty?        500 non-null int64\n",
      "distance_to_customer_KM    450 non-null float64\n",
      "delivery_fee               450 non-null float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "missing_data_mod.info()  # .info() gives an insight about which features are categorical and which are numerical.\n",
    "                         # but we can also see that about 200 values are missing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding similar type of columns to the missing_data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to missing_data_mod with all values assigned to 0.\n",
    "missing_data_mod['time_of_day']=[0]*missing_data_mod.shape[0]\n",
    "\n",
    "for a,b in missing_data_mod.iterrows():\n",
    "    meal=b['order_type']\n",
    "    \n",
    "    #if meal is equal to Breakfast then assinging value 0 to the column 'time_of_day'\n",
    "    if meal=='Breakfast':\n",
    "        missing_data_mod.iloc[a,12]=0\n",
    "\n",
    "    #if meal is equal to Lunch then assinging value 1 to the column 'time_of_day'\n",
    "    if meal=='Lunch':\n",
    "        missing_data_mod.iloc[a,12]=1\n",
    "        \n",
    "    #if meal is equal to Dinner then assinging value 2 to the column 'time_of_day'\n",
    "    if meal =='Dinner':\n",
    "        missing_data_mod.iloc[a,12]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_mod['weekend_weekday']=[0]*missing_data_mod.shape[0]\n",
    "\n",
    "for a,b in missing_data_mod.iterrows():\n",
    "    time=b['date']\n",
    "    \n",
    "    df = pd.Timestamp(time)\n",
    "    day=df.dayofweek\n",
    "    \n",
    "    #if it is a weekday( 0,1,2,3,4) then assigning the value 0 to the column 'weekend_weekday'\n",
    "    if (day==0) or (day==1) or (day==1) or (day==2) or (day==3) or (day==4):\n",
    "        missing_data_mod.iloc[a,13]=0\n",
    "        \n",
    "    #if it is a weekend(5,6) then assigning the value 1 to the column 'weekend_weekday\n",
    "    if (day==5) or (day==6):\n",
    "        missing_data_mod.iloc[a,13]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the rows which have missing values so that we bulid our model on the correct information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.dropna removes the rows with missing values \n",
    "# axis =0 means rows \n",
    "# how ='any'  means if at least 1 null value is present in the row, drop it.\n",
    "#inplace=true means do the opeartion inplace\n",
    "\n",
    "missing_data_mod.dropna( axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next step , we create 3 dataframes w.r.t the branch_code by filtering the missing_data_mod. We need to do this because delievry fee also depends upon the branch and therefore we need to create 3 different models for each branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns=missing_data_mod[missing_data_mod['branch_code']=='NS']\n",
    "tp=missing_data_mod[missing_data_mod['branch_code']=='TP']\n",
    "bk=missing_data_mod[missing_data_mod['branch_code']=='BK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now only take the 4 columns which are required to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = ns[['distance_to_customer_KM','time_of_day','weekend_weekday','delivery_fee']]\n",
    "tp = tp[['distance_to_customer_KM','time_of_day','weekend_weekday','delivery_fee']]\n",
    "bk = bk[['distance_to_customer_KM','time_of_day','weekend_weekday','delivery_fee']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>weekend_weekday</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.808281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.022134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    distance_to_customer_KM  time_of_day  weekend_weekday  delivery_fee\n",
       "7                     9.434            1                0     14.808281\n",
       "14                   10.030            0                0     15.022134"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model for NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<map at 0x1becb5155f8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train_test_spliy split arrays or matrices into random train and test subsets with 80% for training and 20 % for testing\n",
    "#map will convert  into uniform format\n",
    "\n",
    "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(ns.iloc[:,:-1],ns.iloc[:,-1:], random_state = 3,train_size=0.8)\n",
    "map(pd.np.shape,[X_train_ns, X_test_ns, y_train_ns, y_test_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to fit the linear model \n",
    "#include the columns other than delivery fee for X_train and take column'delivery_fee' for y_train\n",
    "linear_mod_ns = LinearRegression()  #instatiate \n",
    "lm_ns = linear_mod_ns.fit(X_train_ns[[x for x in X_train_ns.columns if x!= 'delivery_fee']],y_train_ns['delivery_fee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.\n",
    "\n",
    "The definition of R-squared is fairly straight-forward; it is the percentage of the response variable variation that is explained by a linear model. Or:\n",
    "\n",
    "R-squared = Explained variation / Total variation\n",
    "\n",
    "R-squared is always between 0 and 100%:\n",
    "\n",
    "0% indicates that the model explains none of the variability of the response data around its mean. 100% indicates that the model explains all the variability of the response data around its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087388527947259"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ns.score(X_test_ns,y_test_ns) # calculating the r squard value on X_test and y_test\n",
    "# 0.9087  means the model is good enough to predict the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<map at 0x1becb58f550>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train_test_spliy split arrays or matrices into random train and test subsets with 86% for training and 14 % for testing\n",
    "#map will convert  into uniform format\n",
    "\n",
    "X_train_tp, X_test_tp, y_train_tp, y_test_tp = train_test_split(tp.iloc[:,:-1],tp.iloc[:,-1:], random_state=0,train_size=0.86)\n",
    "map(pd.np.shape,[X_train_tp, X_test_tp, y_train_tp, y_test_tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to fit the linear model \n",
    "#include the columns other than delivery fee for X_train and take column'delivery_fee' for y_train\n",
    "\n",
    "linear_mod_tp=LinearRegression() #instatiate \n",
    "lm_tp = linear_mod_tp.fit(X_train_tp[[x for x in X_train_tp.columns if x!= 'delivery_fee']],y_train_tp['delivery_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6941741890107581"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_tp.score(X_test_tp,y_test_tp)# calculating the r squard value on X_test and y_test\n",
    "# 0.69  means the model is fair enough to predict the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for BK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<map at 0x1becb59a358>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train_test_spliy split arrays or matrices into random train and test subsets with 83% for training and 17 % for testing.\n",
    "#map will convert  into uniform format\n",
    "\n",
    "X_train_bk, X_test_bk, y_train_bk, y_test_bk = train_test_split(bk.iloc[:,:-1],bk.iloc[:,-1:],random_state=0,train_size=0.83)\n",
    "map(pd.np.shape,[X_train_bk, X_test_bk, y_train_bk, y_test_bk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to fit the linear model \n",
    "#include the columns other than delivery fee for X_train and take column'delivery_fee' for y_train\n",
    "\n",
    "linear_mod_bk=LinearRegression() #instatiate \n",
    "lm_bk=linear_mod_bk.fit(X_train_bk[[x for x in X_train_bk.columns if x!= 'delivery_fee']],y_train_bk['delivery_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360670135955898"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_mod_bk.score(X_test_bk,y_test_bk) # calculating the r squard value on X_test and y_test\n",
    "# 0.836 means the model is good enough to predict the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created all the 3 models and now we will try to predict the values for delivery fee in the dirty_data.\n",
    "After predicting we will calculate the difference between the predicted value and the actual value. If the differnce is in the range(-1.5,1.5) , then we will assign the loyalty to 0(no 50% off on the delivery fee) since prediction can never be 100% true so nearby values should work. If the difference is out of range(-1.5,1.5) then we assign the loyalty to 1 (50% discount on the delivery fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "\n",
    "\n",
    "for x,y in dirty_data.iterrows():\n",
    "    b_code=y['branch_code']  #saving each value of different columns to respective varaibles\n",
    "    d=y['distance_to_customer_KM']\n",
    "    ti=y['time_of_day']\n",
    "    w=y['weekend_weekday']\n",
    "    \n",
    "    \n",
    "    #if branch is NS then we use.predict() and pass the array(distance, time of day, weeken_weekday)\n",
    "    # we calculate and store the difference of actual and the predicted value of delivery fee\n",
    "    # assign the value to customerHasloyalty? according to the 2 conditions explained above.\n",
    "    if b_code=='NS':\n",
    "        \n",
    "        predict_ns=lm_ns.predict(np.array([[d,ti,w]]))\n",
    "        difference_ns=dirty_data.iloc[x,11] - predict_ns\n",
    "        \n",
    "        if difference_ns < -1.5 or difference_ns >1.5:\n",
    "            dirty_data.iloc[x,9]=1\n",
    "        else:\n",
    "            dirty_data.iloc[x,9]=0\n",
    "    \n",
    "    \n",
    "    #if branch is TP then we use.predict() and pass the array(distance, time of day, weeken_weekday)\n",
    "    # we calculate and store the difference of actual and the predicted value of delivery fee\n",
    "    # assign the value to customerHasloyalty? according to the 2 conditions explained above.\n",
    "    if b_code=='TP':\n",
    "        \n",
    "        predict_tp=lm_tp.predict(np.array([[d,ti,w]]))\n",
    "        difference_tp=dirty_data.iloc[x,11] - predict_tp\n",
    "        \n",
    "        if difference_tp < -1.5 or difference_tp >1.5:\n",
    "            dirty_data.iloc[x,9]=1\n",
    "        else:\n",
    "            dirty_data.iloc[x,9]=0\n",
    "            \n",
    "    #if branch is BK then we use.predict() and pass the array(distance, time of day, weeken_weekday)\n",
    "    # we calculate and store the difference of actual and the predicted value of delivery fee\n",
    "    # assign the value to customerHasloyalty? according to the 2 conditions explained above.       \n",
    "    if b_code=='BK':\n",
    "        \n",
    "        predict_bk=lm_bk.predict(np.array([[d,ti,w]]))\n",
    "        difference_bk=dirty_data.iloc[x,11] - predict_bk\n",
    "        \n",
    "        if difference_bk < -1.5 or difference_bk >1.5:\n",
    "            dirty_data.iloc[x,9]=1\n",
    "        else:\n",
    "            dirty_data.iloc[x,9]=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the errors have been fixed, now we drop the extra columns we added and save the dataframe as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data=dirty_data.drop(['customer_node','branch_node','correct_dis_km','time_of_day','weekend_weekday'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.to_csv('Group154_dirty_data_solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and removing outlier rows in outlier_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers are found w.r.t delivery fee. Since delivery fee is dependent variable so it is wise to find out the outliers of the residual (difference between the actual and predicted value of delievry fee). We will use the same 3 models(branch_wise) we created on the missing data and then predict the delivery fee values. After predicting the values we will calculate the difference and store it into the new column 'residual' we create. We will find the outliers branch wise on the residual columns and then remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add 2 columns in a similar way we added in the dirty_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to outlier_data with all values assigned to 0.\n",
    "outlier_data['time_of_day']=[0]*outlier_data.shape[0]\n",
    "\n",
    "for a,b in outlier_data.iterrows():\n",
    "    meal=b['order_type']\n",
    "    \n",
    "    #if meal is equal to Breakfast then assinging value 0 to the column 'time_of_day'\n",
    "    if meal=='Breakfast':\n",
    "        outlier_data.iloc[a,12]=0\n",
    "    \n",
    "    #if meal is equal to Lunch then assinging value 1 to the column 'time_of_day'\n",
    "    if meal=='Lunch':\n",
    "        outlier_data.iloc[a,12]=1\n",
    "        \n",
    "    #if meal is equal to Dinner then assinging value 2 to the column 'time_of_day'    \n",
    "    if meal =='Dinner':\n",
    "        outlier_data.iloc[a,12]=2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to outlier_data with all values assigned to 0.\n",
    "outlier_data['weekend_weekday']=[0]*outlier_data.shape[0]\n",
    "\n",
    "for a,b in outlier_data.iterrows():\n",
    "    time=b['date']\n",
    "    \n",
    "    df = pd.Timestamp(time)\n",
    "    day=df.dayofweek\n",
    "    \n",
    "\n",
    "    #if it is a weekday( 0,1,2,3,4) then assigning the value 0 to the column 'weekend_weekday'\n",
    "    if (day==0) or (day==1) or (day==1) or (day==2) or (day==3) or (day==4):\n",
    "        outlier_data.iloc[a,13]=0\n",
    "        \n",
    "    #if it is a weekend(5,6) then assigning the value 1 to the column 'weekend_weekday\n",
    "    if (day==5) or (day==6):\n",
    "        outlier_data.iloc[a,13]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add another column 'residual' and assigning all the values to be 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data['residual']=[0]*outlier_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same 3 models and we predict the values for delivery fee in the outlier_data. After predicting we will first check whether the customer has loyalty or not. IF loyalty is 0 then we will calculate the difference between the predicted value and the actual value and if loyalty is 1 , then we will calculate the difference between the (predicted value/2) and the actual value since loyalty being 1 means customer has 50% off on the delievry fee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in outlier_data.iterrows():\n",
    "    #performing iteration on every row of the data to check and filter out the outliers of the delivery fee\n",
    "    loyal = y['customerHasloyalty?']\n",
    "    #customer loyalty is stored in variable named 'loyal' used to predict the delivery charge and provide discount \n",
    "    b_code=y['branch_code']\n",
    "    #branch code is saved in 'b_code' variable used to use the respective model for prediction\n",
    "    d=y['distance_to_customer_KM']\n",
    "    #distance is stored to calculate the delivery fee\n",
    "    ti=y['time_of_day']\n",
    "    w=y['weekend_weekday']\n",
    "    #time of day and weekday used in prediction model is stored in variable ti and w\n",
    "    \n",
    "    if b_code=='NS':\n",
    "        #residual (difference between actual and predicted delivery fee) for branch with branch code 'NS'\n",
    "        pred_ns=lm_ns.predict(np.array([[d,ti,w]]))\n",
    "        if loyal==0:\n",
    "            #if customer loyalty is zero, no discount applied and delivery fee will be as predicted\n",
    "            residual_ns = outlier_data.iloc[x,11] - pred_ns\n",
    "            #residual will be calculated using the predicted value\n",
    "        else:\n",
    "            #otherwise, customers with loyalty card will get 50% dicsount on delivery fee\n",
    "            residual_ns = outlier_data.iloc[x,11] - (pred_ns/2)\n",
    "            #residual will be calculated using the half of the predicted value\n",
    "        outlier_data.iloc[x,14] = residual_ns\n",
    "        #storing the residual value to the residual column added to the dataframe\n",
    "    \n",
    "    if b_code=='TP':\n",
    "        #residual (difference between actual and predicted delivery fee) for branch with branch code 'TP'\n",
    "        pred_tp=lm_tp.predict(np.array([[d,ti,w]]))\n",
    "        if loyal==0:\n",
    "            #if customer loyalty is zero, no discount applied and delivery fee will be as predicted\n",
    "            residual_tp=outlier_data.iloc[x,11] - pred_tp\n",
    "            #residual will be calculated using the predicted value\n",
    "        else:\n",
    "            #otherwise, customers with loyalty card will get 50% dicsount on delivery fee\n",
    "            residual_tp=outlier_data.iloc[x,11] - (pred_tp/2)\n",
    "            #residual will be calculated using the half of the predicted value\n",
    "        outlier_data.iloc[x,14] = residual_tp\n",
    "        #storing the residual value to the residual column added to the dataframe\n",
    "        \n",
    "            \n",
    "    if b_code=='BK':\n",
    "        #residual (difference between actual and predicted delivery fee) for branch with branch code 'BK'\n",
    "        pred_bk=lm_bk.predict(np.array([[d,ti,w]]))\n",
    "        if loyal==0:\n",
    "            #if customer loyalty is zero, no discount applied and delivery fee will be as predicted\n",
    "            residual_bk=outlier_data.iloc[x,11] - pred_bk\n",
    "            #residual will be calculated using the predicted value\n",
    "        else:\n",
    "            #otherwise, customers with loyalty card will get 50% dicsount on delivery fee\n",
    "            residual_bk=outlier_data.iloc[x,11] - (pred_bk/2)\n",
    "            #residual will be calculated using the half of the predicted value\n",
    "        outlier_data.iloc[x,14] = residual_bk\n",
    "        #storing the residual value to the residual column added to the dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>weekend_weekday</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORDC03038</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>11:02:32</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Eggs', 5), ('Pancake', 10)]</td>\n",
       "      <td>352.50</td>\n",
       "      <td>-37.812274</td>\n",
       "      <td>144.989074</td>\n",
       "      <td>0</td>\n",
       "      <td>8.737</td>\n",
       "      <td>13.376205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORDA07743</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>12:54:05</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Steak', 4), ('Chicken', 4), ('Burger', 7), ...</td>\n",
       "      <td>769.00</td>\n",
       "      <td>-37.804380</td>\n",
       "      <td>144.929732</td>\n",
       "      <td>0</td>\n",
       "      <td>10.562</td>\n",
       "      <td>16.460243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORDI05524</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>09:21:07</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Cereal', 8), ('Eggs', 8), ('Coffee', 7)]</td>\n",
       "      <td>396.50</td>\n",
       "      <td>-37.807646</td>\n",
       "      <td>144.954601</td>\n",
       "      <td>0</td>\n",
       "      <td>8.248</td>\n",
       "      <td>13.185125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORDI06303</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>15:26:11</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Fries', 4), ('Chicken', 7), ('Burger', 2), ...</td>\n",
       "      <td>679.40</td>\n",
       "      <td>-37.813534</td>\n",
       "      <td>144.969359</td>\n",
       "      <td>0</td>\n",
       "      <td>7.684</td>\n",
       "      <td>14.961276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORDZ08782</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>11:22:49</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Cereal', 9), ('Coffee', 5), ('Eggs', 8), ('...</td>\n",
       "      <td>645.00</td>\n",
       "      <td>-37.810355</td>\n",
       "      <td>144.969275</td>\n",
       "      <td>0</td>\n",
       "      <td>7.237</td>\n",
       "      <td>12.269602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORDA06891</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>08:30:25</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Cereal', 10), ('Eggs', 1), ('Pancake', 7)]</td>\n",
       "      <td>401.75</td>\n",
       "      <td>-37.823537</td>\n",
       "      <td>144.980873</td>\n",
       "      <td>0</td>\n",
       "      <td>6.984</td>\n",
       "      <td>12.103057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.103528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORDY01417</td>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>08:20:16</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Pancake', 9), ('Coffee', 1), ('Eggs', 6)]</td>\n",
       "      <td>357.75</td>\n",
       "      <td>-37.819273</td>\n",
       "      <td>144.988521</td>\n",
       "      <td>1</td>\n",
       "      <td>9.472</td>\n",
       "      <td>7.300420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.176888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORDA07013</td>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>15:36:20</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Salad', 3), ('Steak', 4), ('Chicken', 4), (...</td>\n",
       "      <td>607.60</td>\n",
       "      <td>-37.804300</td>\n",
       "      <td>144.945835</td>\n",
       "      <td>0</td>\n",
       "      <td>9.060</td>\n",
       "      <td>17.580106</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORDJ04617</td>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>19:29:34</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Fish&amp;Chips', 3), ('Shrimp', 9)]</td>\n",
       "      <td>591.00</td>\n",
       "      <td>-37.824387</td>\n",
       "      <td>144.943728</td>\n",
       "      <td>0</td>\n",
       "      <td>9.150</td>\n",
       "      <td>14.915326</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.241447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORDY04176</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>16:16:54</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Fish&amp;Chips', 5), ('Shrimp', 6), ('Salmon', ...</td>\n",
       "      <td>869.00</td>\n",
       "      <td>-37.810193</td>\n",
       "      <td>144.961383</td>\n",
       "      <td>0</td>\n",
       "      <td>8.501</td>\n",
       "      <td>14.338527</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORDC03307</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>13:14:21</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Salad', 2), ('Fries', 10), ('Chicken', 8), ...</td>\n",
       "      <td>734.40</td>\n",
       "      <td>-37.823965</td>\n",
       "      <td>144.943758</td>\n",
       "      <td>0</td>\n",
       "      <td>10.578</td>\n",
       "      <td>16.169561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORDX03816</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>11:43:05</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Eggs', 3), ('Cereal', 10), ('Coffee', 7)]</td>\n",
       "      <td>328.50</td>\n",
       "      <td>-37.811521</td>\n",
       "      <td>144.957735</td>\n",
       "      <td>0</td>\n",
       "      <td>8.331</td>\n",
       "      <td>6.547276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.648045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORDC01230</td>\n",
       "      <td>2018-06-25</td>\n",
       "      <td>13:44:47</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Salad', 9), ('Burger', 2), ('Chicken', 5), ...</td>\n",
       "      <td>736.80</td>\n",
       "      <td>-37.804555</td>\n",
       "      <td>144.916041</td>\n",
       "      <td>0</td>\n",
       "      <td>11.576</td>\n",
       "      <td>17.173876</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORDC02506</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>13:54:55</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Burger', 10), ('Steak', 4), ('Chicken', 9),...</td>\n",
       "      <td>970.40</td>\n",
       "      <td>-37.812514</td>\n",
       "      <td>144.936229</td>\n",
       "      <td>0</td>\n",
       "      <td>10.064</td>\n",
       "      <td>17.542964</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORDJ03791</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>13:04:13</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Chicken', 6), ('Salad', 4), ('Burger', 9), ...</td>\n",
       "      <td>575.80</td>\n",
       "      <td>-37.811423</td>\n",
       "      <td>144.929219</td>\n",
       "      <td>0</td>\n",
       "      <td>11.883</td>\n",
       "      <td>15.075784</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORDA01784</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>10:32:06</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Pancake', 9), ('Coffee', 3), ('Eggs', 7)]</td>\n",
       "      <td>394.75</td>\n",
       "      <td>-37.817891</td>\n",
       "      <td>144.961965</td>\n",
       "      <td>0</td>\n",
       "      <td>7.951</td>\n",
       "      <td>12.611051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ORDK09342</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>14:45:38</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Burger', 10), ('Chicken', 5)]</td>\n",
       "      <td>470.00</td>\n",
       "      <td>-37.803927</td>\n",
       "      <td>144.949620</td>\n",
       "      <td>0</td>\n",
       "      <td>8.829</td>\n",
       "      <td>14.585977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORDK06149</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>17:58:18</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Fish&amp;Chips', 2), ('Salmon', 3)]</td>\n",
       "      <td>193.00</td>\n",
       "      <td>-37.821645</td>\n",
       "      <td>144.994491</td>\n",
       "      <td>0</td>\n",
       "      <td>5.661</td>\n",
       "      <td>12.638477</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.409191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORDI08369</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>10:11:49</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pancake', 7), ('Cereal', 3)]</td>\n",
       "      <td>232.75</td>\n",
       "      <td>-37.799881</td>\n",
       "      <td>145.008980</td>\n",
       "      <td>0</td>\n",
       "      <td>10.059</td>\n",
       "      <td>14.867130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORDZ06972</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>08:40:33</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Cereal', 6), ('Coffee', 10)]</td>\n",
       "      <td>201.00</td>\n",
       "      <td>-37.812087</td>\n",
       "      <td>144.945178</td>\n",
       "      <td>0</td>\n",
       "      <td>9.110</td>\n",
       "      <td>13.080445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.288935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ORDK02666</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>10:21:58</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Cereal', 7), ('Coffee', 4)]</td>\n",
       "      <td>177.00</td>\n",
       "      <td>-37.813032</td>\n",
       "      <td>144.951469</td>\n",
       "      <td>0</td>\n",
       "      <td>8.554</td>\n",
       "      <td>13.416837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.023548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ORDJ00492</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>14:15:12</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Burger', 7), ('Chicken', 9), ('Fries', 6), ...</td>\n",
       "      <td>1023.00</td>\n",
       "      <td>-37.803208</td>\n",
       "      <td>144.973875</td>\n",
       "      <td>0</td>\n",
       "      <td>9.780</td>\n",
       "      <td>12.817471</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ORDY01946</td>\n",
       "      <td>2018-08-26</td>\n",
       "      <td>15:46:28</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Steak', 8), ('Salad', 1), ('Fries', 8), ('C...</td>\n",
       "      <td>881.20</td>\n",
       "      <td>-37.812337</td>\n",
       "      <td>144.938523</td>\n",
       "      <td>0</td>\n",
       "      <td>10.875</td>\n",
       "      <td>15.477298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ORDB04361</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>13:34:38</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salad', 7), ('Chicken', 7)]</td>\n",
       "      <td>344.40</td>\n",
       "      <td>-37.816416</td>\n",
       "      <td>144.945902</td>\n",
       "      <td>0</td>\n",
       "      <td>9.482</td>\n",
       "      <td>12.913134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ORDB03745</td>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>16:06:45</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Fish&amp;Chips', 7), ('Pasta', 1)]</td>\n",
       "      <td>272.50</td>\n",
       "      <td>-37.813443</td>\n",
       "      <td>144.965624</td>\n",
       "      <td>0</td>\n",
       "      <td>8.214</td>\n",
       "      <td>14.365046</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ORDX07918</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>17:27:53</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Fish&amp;Chips', 9), ('Salmon', 2), ('Pasta', 9...</td>\n",
       "      <td>914.50</td>\n",
       "      <td>-37.817980</td>\n",
       "      <td>144.966835</td>\n",
       "      <td>0</td>\n",
       "      <td>7.533</td>\n",
       "      <td>14.201631</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.507896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ORDX02469</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>12:43:56</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Chicken', 7), ('Salad', 9)]</td>\n",
       "      <td>378.80</td>\n",
       "      <td>-37.800196</td>\n",
       "      <td>144.933813</td>\n",
       "      <td>0</td>\n",
       "      <td>12.347</td>\n",
       "      <td>9.270787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.101033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ORDX00772</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>09:10:59</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Cereal', 3), ('Eggs', 4), ('Coffee', 6), ('...</td>\n",
       "      <td>317.25</td>\n",
       "      <td>-37.821758</td>\n",
       "      <td>144.981199</td>\n",
       "      <td>0</td>\n",
       "      <td>7.016</td>\n",
       "      <td>12.032605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.004668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ORDX00782</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>17:58:18</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Shrimp', 9), ('Pasta', 10), ('Salmon', 7), ...</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>-37.804417</td>\n",
       "      <td>144.934691</td>\n",
       "      <td>0</td>\n",
       "      <td>10.072</td>\n",
       "      <td>17.140158</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ORDJ00824</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>13:24:30</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Fries', 2), ('Salad', 3)]</td>\n",
       "      <td>75.60</td>\n",
       "      <td>-37.811393</td>\n",
       "      <td>144.953334</td>\n",
       "      <td>0</td>\n",
       "      <td>8.957</td>\n",
       "      <td>12.078693</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>ORDX08593</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>09:51:32</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Coffee', 1), ('Cereal', 9), ('Eggs', 5), ('...</td>\n",
       "      <td>355.00</td>\n",
       "      <td>-37.815067</td>\n",
       "      <td>144.974785</td>\n",
       "      <td>0</td>\n",
       "      <td>6.722</td>\n",
       "      <td>11.838018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.071078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>ORDZ07428</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>13:04:13</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Chicken', 5), ('Steak', 8), ('Burger', 3)]</td>\n",
       "      <td>613.00</td>\n",
       "      <td>-37.815471</td>\n",
       "      <td>144.967072</td>\n",
       "      <td>0</td>\n",
       "      <td>8.234</td>\n",
       "      <td>15.585495</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ORDZ07470</td>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>09:41:24</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pancake', 1), ('Coffee', 6)]</td>\n",
       "      <td>69.25</td>\n",
       "      <td>-37.806387</td>\n",
       "      <td>144.932407</td>\n",
       "      <td>0</td>\n",
       "      <td>10.177</td>\n",
       "      <td>15.005495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>ORDX09433</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>12:54:05</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Burger', 8), ('Steak', 4)]</td>\n",
       "      <td>428.00</td>\n",
       "      <td>-37.810240</td>\n",
       "      <td>145.010334</td>\n",
       "      <td>0</td>\n",
       "      <td>3.632</td>\n",
       "      <td>9.381640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>ORDY09699</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>18:49:00</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Pasta', 6), ('Fish&amp;Chips', 5)]</td>\n",
       "      <td>340.00</td>\n",
       "      <td>-37.813715</td>\n",
       "      <td>144.940212</td>\n",
       "      <td>0</td>\n",
       "      <td>10.108</td>\n",
       "      <td>15.374301</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.008740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>ORDJ07695</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>14:55:46</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Burger', 2), ('Steak', 2), ('Salad', 8), ('...</td>\n",
       "      <td>469.60</td>\n",
       "      <td>-37.805491</td>\n",
       "      <td>144.973646</td>\n",
       "      <td>0</td>\n",
       "      <td>9.517</td>\n",
       "      <td>12.238987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.313439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ORDI04326</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>10:21:58</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Cereal', 4), ('Pancake', 7), ('Coffee', 3),...</td>\n",
       "      <td>298.25</td>\n",
       "      <td>-37.824594</td>\n",
       "      <td>144.982186</td>\n",
       "      <td>0</td>\n",
       "      <td>9.454</td>\n",
       "      <td>14.384486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>ORDX08158</td>\n",
       "      <td>2018-12-16</td>\n",
       "      <td>19:29:34</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Fish&amp;Chips', 6), ('Shrimp', 8)]</td>\n",
       "      <td>642.00</td>\n",
       "      <td>-37.824379</td>\n",
       "      <td>144.944289</td>\n",
       "      <td>0</td>\n",
       "      <td>9.829</td>\n",
       "      <td>19.518283</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.385369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>ORDX10923</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>17:07:36</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Pasta', 3), ('Shrimp', 3), ('Fish&amp;Chips', 1...</td>\n",
       "      <td>799.50</td>\n",
       "      <td>-37.808929</td>\n",
       "      <td>144.966257</td>\n",
       "      <td>0</td>\n",
       "      <td>7.160</td>\n",
       "      <td>13.976413</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.401985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>ORDZ03776</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>18:28:43</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Salmon', 2), ('Pasta', 9), ('Fish&amp;Chips', 6...</td>\n",
       "      <td>1079.50</td>\n",
       "      <td>-37.812370</td>\n",
       "      <td>144.961740</td>\n",
       "      <td>0</td>\n",
       "      <td>7.891</td>\n",
       "      <td>13.979623</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>ORDB06506</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>18:08:27</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salmon', 10), ('Pasta', 9), ('Fish&amp;Chips', ...</td>\n",
       "      <td>1442.50</td>\n",
       "      <td>-37.815656</td>\n",
       "      <td>144.954354</td>\n",
       "      <td>0</td>\n",
       "      <td>8.580</td>\n",
       "      <td>6.459566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.731830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>ORDZ00286</td>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>16:06:45</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Fish&amp;Chips', 6), ('Salmon', 8)]</td>\n",
       "      <td>538.00</td>\n",
       "      <td>-37.814111</td>\n",
       "      <td>144.963266</td>\n",
       "      <td>0</td>\n",
       "      <td>8.058</td>\n",
       "      <td>16.107729</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.115907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ORDA03385</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>11:43:05</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Cereal', 9), ('Eggs', 6), ('Coffee', 4), ('...</td>\n",
       "      <td>399.50</td>\n",
       "      <td>-37.818839</td>\n",
       "      <td>144.953106</td>\n",
       "      <td>0</td>\n",
       "      <td>8.821</td>\n",
       "      <td>16.235375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.219935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>ORDI07974</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>14:35:29</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Burger', 2), ('Steak', 7), ('Fries', 4), ('...</td>\n",
       "      <td>853.00</td>\n",
       "      <td>-37.808456</td>\n",
       "      <td>144.938222</td>\n",
       "      <td>0</td>\n",
       "      <td>10.169</td>\n",
       "      <td>17.924109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>ORDZ02051</td>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>11:53:14</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Cereal', 6), ('Pancake', 3), ('Coffee', 2),...</td>\n",
       "      <td>433.75</td>\n",
       "      <td>-37.818105</td>\n",
       "      <td>144.980233</td>\n",
       "      <td>0</td>\n",
       "      <td>8.630</td>\n",
       "      <td>15.009375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>ORDC02288</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>19:39:43</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Shrimp', 4), ('Salmon', 4), ('Pasta', 8), (...</td>\n",
       "      <td>880.00</td>\n",
       "      <td>-37.814828</td>\n",
       "      <td>144.932784</td>\n",
       "      <td>0</td>\n",
       "      <td>9.153</td>\n",
       "      <td>15.317905</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>ORDK03294</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>15:26:11</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Chicken', 8), ('Burger', 5)]</td>\n",
       "      <td>411.00</td>\n",
       "      <td>-37.810092</td>\n",
       "      <td>144.996006</td>\n",
       "      <td>0</td>\n",
       "      <td>4.488</td>\n",
       "      <td>9.838450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.556580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>ORDZ01057</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>10:01:41</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Coffee', 3), ('Eggs', 2), ('Pancake', 1)]</td>\n",
       "      <td>90.75</td>\n",
       "      <td>-37.799279</td>\n",
       "      <td>144.936797</td>\n",
       "      <td>0</td>\n",
       "      <td>9.230</td>\n",
       "      <td>13.410168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ORDK06276</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>17:17:44</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Salmon', 6), ('Pasta', 6), ('Fish&amp;Chips', 4)]</td>\n",
       "      <td>551.00</td>\n",
       "      <td>-37.812655</td>\n",
       "      <td>144.925244</td>\n",
       "      <td>0</td>\n",
       "      <td>11.257</td>\n",
       "      <td>18.431482</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>ORDC07534</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>12:54:05</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Salad', 7), ('Steak', 4)]</td>\n",
       "      <td>300.40</td>\n",
       "      <td>-37.801164</td>\n",
       "      <td>145.009123</td>\n",
       "      <td>0</td>\n",
       "      <td>9.803</td>\n",
       "      <td>15.251971</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>ORDY00730</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>11:32:57</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Coffee', 1), ('Pancake', 4), ('Eggs', 3)]</td>\n",
       "      <td>170.50</td>\n",
       "      <td>-37.818906</td>\n",
       "      <td>144.953311</td>\n",
       "      <td>0</td>\n",
       "      <td>8.513</td>\n",
       "      <td>6.209426</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.327735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>ORDI08920</td>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>13:54:55</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Salad', 9), ('Burger', 3), ('Steak', 10), (...</td>\n",
       "      <td>1017.80</td>\n",
       "      <td>-37.817403</td>\n",
       "      <td>144.952611</td>\n",
       "      <td>0</td>\n",
       "      <td>9.046</td>\n",
       "      <td>14.411403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>ORDY01344</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>11:02:32</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Coffee', 1), ('Pancake', 10)]</td>\n",
       "      <td>250.00</td>\n",
       "      <td>-37.810524</td>\n",
       "      <td>144.985314</td>\n",
       "      <td>0</td>\n",
       "      <td>9.657</td>\n",
       "      <td>12.605681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.282208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>ORDC07543</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>18:08:27</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pasta', 4), ('Fish&amp;Chips', 5), ('Salmon', 8)]</td>\n",
       "      <td>613.00</td>\n",
       "      <td>-37.811417</td>\n",
       "      <td>144.952007</td>\n",
       "      <td>0</td>\n",
       "      <td>8.566</td>\n",
       "      <td>16.769545</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>ORDI00316</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>17:58:18</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pasta', 9), ('Shrimp', 2)]</td>\n",
       "      <td>355.50</td>\n",
       "      <td>-37.816467</td>\n",
       "      <td>144.997220</td>\n",
       "      <td>0</td>\n",
       "      <td>9.801</td>\n",
       "      <td>15.529090</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.320309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ORDX06251</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Fish&amp;Chips', 9), ('Salmon', 2)]</td>\n",
       "      <td>397.00</td>\n",
       "      <td>-37.804754</td>\n",
       "      <td>145.003215</td>\n",
       "      <td>0</td>\n",
       "      <td>5.051</td>\n",
       "      <td>11.536499</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.969645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ORDA02347</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>12:33:48</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Steak', 6), ('Salad', 8), ('Burger', 1), ('...</td>\n",
       "      <td>718.60</td>\n",
       "      <td>-37.801967</td>\n",
       "      <td>144.957310</td>\n",
       "      <td>0</td>\n",
       "      <td>8.184</td>\n",
       "      <td>16.695726</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ORDC06982</td>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>11:53:14</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pancake', 5), ('Eggs', 7), ('Cereal', 5)]</td>\n",
       "      <td>380.25</td>\n",
       "      <td>-37.819893</td>\n",
       "      <td>145.012539</td>\n",
       "      <td>0</td>\n",
       "      <td>11.247</td>\n",
       "      <td>18.401199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ORDI07886</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>14:45:38</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Chicken', 10), ('Fries', 1), ('Salad', 7)]</td>\n",
       "      <td>452.40</td>\n",
       "      <td>-37.822333</td>\n",
       "      <td>144.975541</td>\n",
       "      <td>0</td>\n",
       "      <td>9.132</td>\n",
       "      <td>14.711195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ORDB02564</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>10:32:06</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Pancake', 9), ('Cereal', 5), ('Coffee', 8),...</td>\n",
       "      <td>515.25</td>\n",
       "      <td>-37.801539</td>\n",
       "      <td>144.948012</td>\n",
       "      <td>0</td>\n",
       "      <td>10.208</td>\n",
       "      <td>12.640380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id        date      time order_type branch_code  \\\n",
       "0    ORDC03038  2018-04-03  11:02:32  Breakfast          NS   \n",
       "1    ORDA07743  2018-05-30  12:54:05      Lunch          BK   \n",
       "2    ORDI05524  2018-02-12  09:21:07  Breakfast          NS   \n",
       "3    ORDI06303  2018-08-12  15:26:11      Lunch          NS   \n",
       "4    ORDZ08782  2018-04-16  11:22:49  Breakfast          NS   \n",
       "5    ORDA06891  2018-01-19  08:30:25  Breakfast          BK   \n",
       "6    ORDY01417  2018-01-13  08:20:16  Breakfast          TP   \n",
       "7    ORDA07013  2018-08-19  15:36:20      Lunch          BK   \n",
       "8    ORDJ04617  2018-12-15  19:29:34     Dinner          TP   \n",
       "9    ORDY04176  2018-09-09  16:16:54     Dinner          TP   \n",
       "10   ORDC03307  2018-06-11  13:14:21      Lunch          NS   \n",
       "11   ORDX03816  2018-04-24  11:43:05  Breakfast          BK   \n",
       "12   ORDC01230  2018-06-25  13:44:47      Lunch          NS   \n",
       "13   ORDC02506  2018-06-30  13:54:55      Lunch          NS   \n",
       "14   ORDJ03791  2018-06-05  13:04:13      Lunch          TP   \n",
       "15   ORDA01784  2018-03-22  10:32:06  Breakfast          BK   \n",
       "16   ORDK09342  2018-07-24  14:45:38      Lunch          BK   \n",
       "17   ORDK06149  2018-10-30  17:58:18     Dinner          BK   \n",
       "18   ORDI08369  2018-03-09  10:11:49  Breakfast          NS   \n",
       "19   ORDZ06972  2018-01-25  08:40:33  Breakfast          NS   \n",
       "20   ORDK02666  2018-03-14  10:21:58  Breakfast          BK   \n",
       "21   ORDJ00492  2018-07-11  14:15:12      Lunch          TP   \n",
       "22   ORDY01946  2018-08-26  15:46:28      Lunch          TP   \n",
       "23   ORDB04361  2018-06-21  13:34:38      Lunch          TP   \n",
       "24   ORDB03745  2018-09-02  16:06:45     Dinner          TP   \n",
       "25   ORDX07918  2018-10-12  17:27:53     Dinner          BK   \n",
       "26   ORDX02469  2018-05-24  12:43:56      Lunch          BK   \n",
       "27   ORDX00772  2018-02-08  09:10:59  Breakfast          BK   \n",
       "28   ORDX00782  2018-10-31  17:58:18     Dinner          BK   \n",
       "29   ORDJ00824  2018-06-13  13:24:30      Lunch          TP   \n",
       "..         ...         ...       ...        ...         ...   \n",
       "470  ORDX08593  2018-03-01  09:51:32  Breakfast          BK   \n",
       "471  ORDZ07428  2018-06-02  13:04:13      Lunch          NS   \n",
       "472  ORDZ07470  2018-02-23  09:41:24  Breakfast          NS   \n",
       "473  ORDX09433  2018-05-29  12:54:05      Lunch          BK   \n",
       "474  ORDY09699  2018-11-24  18:49:00     Dinner          TP   \n",
       "475  ORDJ07695  2018-08-01  14:55:46      Lunch          TP   \n",
       "476  ORDI04326  2018-03-13  10:21:58  Breakfast          NS   \n",
       "477  ORDX08158  2018-12-16  19:29:34     Dinner          BK   \n",
       "478  ORDX10923  2018-10-05  17:07:36     Dinner          BK   \n",
       "479  ORDZ03776  2018-11-13  18:28:43     Dinner          NS   \n",
       "480  ORDB06506  2018-11-01  18:08:27     Dinner          TP   \n",
       "481  ORDZ00286  2018-09-02  16:06:45     Dinner          NS   \n",
       "482  ORDA03385  2018-04-22  11:43:05  Breakfast          BK   \n",
       "483  ORDI07974  2018-07-21  14:35:29      Lunch          NS   \n",
       "484  ORDZ02051  2018-04-28  11:53:14  Breakfast          NS   \n",
       "485  ORDC02288  2018-12-21  19:39:43     Dinner          NS   \n",
       "486  ORDK03294  2018-08-16  15:26:11      Lunch          BK   \n",
       "487  ORDZ01057  2018-03-05  10:01:41  Breakfast          NS   \n",
       "488  ORDK06276  2018-10-09  17:17:44     Dinner          BK   \n",
       "489  ORDC07534  2018-05-31  12:54:05      Lunch          NS   \n",
       "490  ORDY00730  2018-04-22  11:32:57  Breakfast          TP   \n",
       "491  ORDI08920  2018-07-02  13:54:55      Lunch          NS   \n",
       "492  ORDY01344  2018-04-03  11:02:32  Breakfast          TP   \n",
       "493  ORDC07543  2018-11-03  18:08:27     Dinner          NS   \n",
       "494  ORDI00316  2018-11-01  17:58:18     Dinner          NS   \n",
       "495  ORDX06251  2018-12-31  20:00:00     Dinner          BK   \n",
       "496  ORDA02347  2018-05-20  12:33:48      Lunch          BK   \n",
       "497  ORDC06982  2018-04-29  11:53:14  Breakfast          NS   \n",
       "498  ORDI07886  2018-07-25  14:45:38      Lunch          NS   \n",
       "499  ORDB02564  2018-03-19  10:32:06  Breakfast          TP   \n",
       "\n",
       "                                           order_items  order_price  \\\n",
       "0                       [('Eggs', 5), ('Pancake', 10)]       352.50   \n",
       "1    [('Steak', 4), ('Chicken', 4), ('Burger', 7), ...       769.00   \n",
       "2          [('Cereal', 8), ('Eggs', 8), ('Coffee', 7)]       396.50   \n",
       "3    [('Fries', 4), ('Chicken', 7), ('Burger', 2), ...       679.40   \n",
       "4    [('Cereal', 9), ('Coffee', 5), ('Eggs', 8), ('...       645.00   \n",
       "5        [('Cereal', 10), ('Eggs', 1), ('Pancake', 7)]       401.75   \n",
       "6         [('Pancake', 9), ('Coffee', 1), ('Eggs', 6)]       357.75   \n",
       "7    [('Salad', 3), ('Steak', 4), ('Chicken', 4), (...       607.60   \n",
       "8                   [('Fish&Chips', 3), ('Shrimp', 9)]       591.00   \n",
       "9    [('Fish&Chips', 5), ('Shrimp', 6), ('Salmon', ...       869.00   \n",
       "10   [('Salad', 2), ('Fries', 10), ('Chicken', 8), ...       734.40   \n",
       "11        [('Eggs', 3), ('Cereal', 10), ('Coffee', 7)]       328.50   \n",
       "12   [('Salad', 9), ('Burger', 2), ('Chicken', 5), ...       736.80   \n",
       "13   [('Burger', 10), ('Steak', 4), ('Chicken', 9),...       970.40   \n",
       "14   [('Chicken', 6), ('Salad', 4), ('Burger', 9), ...       575.80   \n",
       "15        [('Pancake', 9), ('Coffee', 3), ('Eggs', 7)]       394.75   \n",
       "16                    [('Burger', 10), ('Chicken', 5)]       470.00   \n",
       "17                  [('Fish&Chips', 2), ('Salmon', 3)]       193.00   \n",
       "18                     [('Pancake', 7), ('Cereal', 3)]       232.75   \n",
       "19                     [('Cereal', 6), ('Coffee', 10)]       201.00   \n",
       "20                      [('Cereal', 7), ('Coffee', 4)]       177.00   \n",
       "21   [('Burger', 7), ('Chicken', 9), ('Fries', 6), ...      1023.00   \n",
       "22   [('Steak', 8), ('Salad', 1), ('Fries', 8), ('C...       881.20   \n",
       "23                      [('Salad', 7), ('Chicken', 7)]       344.40   \n",
       "24                   [('Fish&Chips', 7), ('Pasta', 1)]       272.50   \n",
       "25   [('Fish&Chips', 9), ('Salmon', 2), ('Pasta', 9...       914.50   \n",
       "26                      [('Chicken', 7), ('Salad', 9)]       378.80   \n",
       "27   [('Cereal', 3), ('Eggs', 4), ('Coffee', 6), ('...       317.25   \n",
       "28   [('Shrimp', 9), ('Pasta', 10), ('Salmon', 7), ...      1118.00   \n",
       "29                        [('Fries', 2), ('Salad', 3)]        75.60   \n",
       "..                                                 ...          ...   \n",
       "470  [('Coffee', 1), ('Cereal', 9), ('Eggs', 5), ('...       355.00   \n",
       "471      [('Chicken', 5), ('Steak', 8), ('Burger', 3)]       613.00   \n",
       "472                    [('Pancake', 1), ('Coffee', 6)]        69.25   \n",
       "473                      [('Burger', 8), ('Steak', 4)]       428.00   \n",
       "474                  [('Pasta', 6), ('Fish&Chips', 5)]       340.00   \n",
       "475  [('Burger', 2), ('Steak', 2), ('Salad', 8), ('...       469.60   \n",
       "476  [('Cereal', 4), ('Pancake', 7), ('Coffee', 3),...       298.25   \n",
       "477                 [('Fish&Chips', 6), ('Shrimp', 8)]       642.00   \n",
       "478  [('Pasta', 3), ('Shrimp', 3), ('Fish&Chips', 1...       799.50   \n",
       "479  [('Salmon', 2), ('Pasta', 9), ('Fish&Chips', 6...      1079.50   \n",
       "480  [('Salmon', 10), ('Pasta', 9), ('Fish&Chips', ...      1442.50   \n",
       "481                 [('Fish&Chips', 6), ('Salmon', 8)]       538.00   \n",
       "482  [('Cereal', 9), ('Eggs', 6), ('Coffee', 4), ('...       399.50   \n",
       "483  [('Burger', 2), ('Steak', 7), ('Fries', 4), ('...       853.00   \n",
       "484  [('Cereal', 6), ('Pancake', 3), ('Coffee', 2),...       433.75   \n",
       "485  [('Shrimp', 4), ('Salmon', 4), ('Pasta', 8), (...       880.00   \n",
       "486                    [('Chicken', 8), ('Burger', 5)]       411.00   \n",
       "487       [('Coffee', 3), ('Eggs', 2), ('Pancake', 1)]        90.75   \n",
       "488   [('Salmon', 6), ('Pasta', 6), ('Fish&Chips', 4)]       551.00   \n",
       "489                       [('Salad', 7), ('Steak', 4)]       300.40   \n",
       "490       [('Coffee', 1), ('Pancake', 4), ('Eggs', 3)]       170.50   \n",
       "491  [('Salad', 9), ('Burger', 3), ('Steak', 10), (...      1017.80   \n",
       "492                   [('Coffee', 1), ('Pancake', 10)]       250.00   \n",
       "493   [('Pasta', 4), ('Fish&Chips', 5), ('Salmon', 8)]       613.00   \n",
       "494                      [('Pasta', 9), ('Shrimp', 2)]       355.50   \n",
       "495                 [('Fish&Chips', 9), ('Salmon', 2)]       397.00   \n",
       "496  [('Steak', 6), ('Salad', 8), ('Burger', 1), ('...       718.60   \n",
       "497       [('Pancake', 5), ('Eggs', 7), ('Cereal', 5)]       380.25   \n",
       "498      [('Chicken', 10), ('Fries', 1), ('Salad', 7)]       452.40   \n",
       "499  [('Pancake', 9), ('Cereal', 5), ('Coffee', 8),...       515.25   \n",
       "\n",
       "     customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "0      -37.812274    144.989074                    0                    8.737   \n",
       "1      -37.804380    144.929732                    0                   10.562   \n",
       "2      -37.807646    144.954601                    0                    8.248   \n",
       "3      -37.813534    144.969359                    0                    7.684   \n",
       "4      -37.810355    144.969275                    0                    7.237   \n",
       "5      -37.823537    144.980873                    0                    6.984   \n",
       "6      -37.819273    144.988521                    1                    9.472   \n",
       "7      -37.804300    144.945835                    0                    9.060   \n",
       "8      -37.824387    144.943728                    0                    9.150   \n",
       "9      -37.810193    144.961383                    0                    8.501   \n",
       "10     -37.823965    144.943758                    0                   10.578   \n",
       "11     -37.811521    144.957735                    0                    8.331   \n",
       "12     -37.804555    144.916041                    0                   11.576   \n",
       "13     -37.812514    144.936229                    0                   10.064   \n",
       "14     -37.811423    144.929219                    0                   11.883   \n",
       "15     -37.817891    144.961965                    0                    7.951   \n",
       "16     -37.803927    144.949620                    0                    8.829   \n",
       "17     -37.821645    144.994491                    0                    5.661   \n",
       "18     -37.799881    145.008980                    0                   10.059   \n",
       "19     -37.812087    144.945178                    0                    9.110   \n",
       "20     -37.813032    144.951469                    0                    8.554   \n",
       "21     -37.803208    144.973875                    0                    9.780   \n",
       "22     -37.812337    144.938523                    0                   10.875   \n",
       "23     -37.816416    144.945902                    0                    9.482   \n",
       "24     -37.813443    144.965624                    0                    8.214   \n",
       "25     -37.817980    144.966835                    0                    7.533   \n",
       "26     -37.800196    144.933813                    0                   12.347   \n",
       "27     -37.821758    144.981199                    0                    7.016   \n",
       "28     -37.804417    144.934691                    0                   10.072   \n",
       "29     -37.811393    144.953334                    0                    8.957   \n",
       "..            ...           ...                  ...                      ...   \n",
       "470    -37.815067    144.974785                    0                    6.722   \n",
       "471    -37.815471    144.967072                    0                    8.234   \n",
       "472    -37.806387    144.932407                    0                   10.177   \n",
       "473    -37.810240    145.010334                    0                    3.632   \n",
       "474    -37.813715    144.940212                    0                   10.108   \n",
       "475    -37.805491    144.973646                    0                    9.517   \n",
       "476    -37.824594    144.982186                    0                    9.454   \n",
       "477    -37.824379    144.944289                    0                    9.829   \n",
       "478    -37.808929    144.966257                    0                    7.160   \n",
       "479    -37.812370    144.961740                    0                    7.891   \n",
       "480    -37.815656    144.954354                    0                    8.580   \n",
       "481    -37.814111    144.963266                    0                    8.058   \n",
       "482    -37.818839    144.953106                    0                    8.821   \n",
       "483    -37.808456    144.938222                    0                   10.169   \n",
       "484    -37.818105    144.980233                    0                    8.630   \n",
       "485    -37.814828    144.932784                    0                    9.153   \n",
       "486    -37.810092    144.996006                    0                    4.488   \n",
       "487    -37.799279    144.936797                    0                    9.230   \n",
       "488    -37.812655    144.925244                    0                   11.257   \n",
       "489    -37.801164    145.009123                    0                    9.803   \n",
       "490    -37.818906    144.953311                    0                    8.513   \n",
       "491    -37.817403    144.952611                    0                    9.046   \n",
       "492    -37.810524    144.985314                    0                    9.657   \n",
       "493    -37.811417    144.952007                    0                    8.566   \n",
       "494    -37.816467    144.997220                    0                    9.801   \n",
       "495    -37.804754    145.003215                    0                    5.051   \n",
       "496    -37.801967    144.957310                    0                    8.184   \n",
       "497    -37.819893    145.012539                    0                   11.247   \n",
       "498    -37.822333    144.975541                    0                    9.132   \n",
       "499    -37.801539    144.948012                    0                   10.208   \n",
       "\n",
       "     delivery_fee  time_of_day  weekend_weekday  residual  \n",
       "0       13.376205            0                0  0.361546  \n",
       "1       16.460243            1                0  0.673049  \n",
       "2       13.185125            0                0  0.635502  \n",
       "3       14.961276            1                1  0.004752  \n",
       "4       12.269602            0                0  0.681435  \n",
       "5       12.103057            0                0  1.103528  \n",
       "6        7.300420            0                1  1.176888  \n",
       "7       17.580106            1                1  0.741182  \n",
       "8       14.915326            2                1  0.241447  \n",
       "9       14.338527            2                1  0.145074  \n",
       "10      16.169561            1                0  0.492679  \n",
       "11       6.547276            0                0 -5.648045  \n",
       "12      17.173876            1                0  0.547901  \n",
       "13      17.542964            1                1  0.323072  \n",
       "14      15.075784            1                0  0.771917  \n",
       "15      12.611051            0                0  0.753073  \n",
       "16      14.585977            1                0  0.337245  \n",
       "17      12.638477            2                0 -0.409191  \n",
       "18      14.867130            0                0  0.595255  \n",
       "19      13.080445            0                0 -0.288935  \n",
       "20      13.416837            0                0  1.023548  \n",
       "21      12.817471            1                0  0.070358  \n",
       "22      15.477298            1                1  0.859069  \n",
       "23      12.913134            1                0  0.386617  \n",
       "24      14.365046            2                1  0.384045  \n",
       "25      14.201631            2                0 -0.507896  \n",
       "26       9.270787            1                0 -8.101033  \n",
       "27      12.032605            0                0  1.004668  \n",
       "28      17.140158            2                0  0.176645  \n",
       "29      12.078693            1                0 -0.059190  \n",
       "..            ...          ...              ...       ...  \n",
       "470     11.838018            0                0  1.071078  \n",
       "471     15.585495            1                1  0.105924  \n",
       "472     15.005495            0                0  0.621402  \n",
       "473      9.381640            1                0 -0.253481  \n",
       "474     15.374301            2                1 -0.008740  \n",
       "475     12.238987            1                0 -0.313439  \n",
       "476     14.384486            0                0  0.687963  \n",
       "477     19.518283            2                1  0.385369  \n",
       "478     13.976413            2                0 -0.401985  \n",
       "479     13.979623            2                0 -0.053376  \n",
       "480      6.459566            2                0 -6.731830  \n",
       "481     16.107729            2                1 -0.115907  \n",
       "482     16.235375            0                1  1.219935  \n",
       "483     17.924109            1                1  0.604363  \n",
       "484     15.009375            0                1  0.064651  \n",
       "485     15.317905            2                0  0.084750  \n",
       "486      9.838450            1                0 -0.556580  \n",
       "487     13.410168            0                0 -0.073332  \n",
       "488     18.431482            2                0  0.415992  \n",
       "489     15.251971            1                0  0.312111  \n",
       "490      6.209426            0                1 -5.327735  \n",
       "491     14.411403            1                0  0.191445  \n",
       "492     12.605681            0                0  1.282208  \n",
       "493     16.769545            2                1  0.062803  \n",
       "494     15.529090            2                0 -0.320309  \n",
       "495     11.536499            2                0 -0.969645  \n",
       "496     16.695726            1                1  0.634467  \n",
       "497     18.401199            0                1  0.967721  \n",
       "498     14.711195            1                0  0.409452  \n",
       "499     12.640380            0                0  0.909027  \n",
       "\n",
       "[500 rows x 15 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to show the boxplot for the delivery fee to get the idea about the outliers.\n",
    "\n",
    "For filtering the outliers we will perform plot on the residual, i.e the difference between the actual value and the predicted one using the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1becbea9a20>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_data.boxplot(by='branch_code', column = 'residual') \n",
    "#boxplot on residual(difference between actual and predicted value) group by branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above boxplot shows the median, 1st,2nd and 3rd quartile range for each branch and the values of the outliers for all three branches induvidually. Branch with branchcode BK has only 4 outlier values, whereas branch with branch code TP has the maximum number of outlier values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see from the plot above that there are some considerable number of outliers in the data for each branch, which needs to be filtered and removed from the data. Wr need to calculate the Upper bounf and Lower bound for the residual to calculate the filter the outliers. This can be calculated using formula:\n",
    "$$UB = Q_3 + 1.5\\times IQR$$\n",
    "\n",
    "\n",
    "$$LB = Q_1 - 1.5\\times IQR$$\n",
    "\n",
    "\n",
    "$$IQR = Q_3 - Q_1$$\n",
    "where, $Q_1$ is first quartile and $Q_4$ is fourth quartile and $IQR$ is the inter quartile range\n",
    "Outliers are the unrealistic values that are not relatable to the data. These values are the values above the upper bound and values less than the lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the quartiles for residual of branch with branch code 'NS'\n",
    "vis_ns=outlier_data[outlier_data['branch_code']=='NS'].residual.describe()\n",
    "#calculating IQR using Q3 and Q1 and using IQR to calculate the upper and lower bound using the formula above\n",
    "iqr_ns = vis_ns[6]-vis_ns[4]\n",
    "ub_ns = vis_ns[6] + 1.5*iqr_ns\n",
    "lb_ns = vis_ns[4] - 1.5*iqr_ns\n",
    "\n",
    "#calculating the quartiles for residual of branch with branch code 'TP'\n",
    "vis_tp=outlier_data[outlier_data['branch_code']=='TP'].residual.describe()\n",
    "#calculating IQR using Q3 and Q1 and using IQR to calculate the upper and lower bound using the formula above\n",
    "iqr_tp = vis_tp[6]-vis_tp[4]\n",
    "ub_tp = vis_tp[6] + 1.5*iqr_tp\n",
    "lb_tp = vis_tp[4] - 1.5*iqr_tp\n",
    "\n",
    "#calculating the quartiles for residual of branch with branch code 'BK'\n",
    "vis_bk=outlier_data[outlier_data['branch_code']=='BK'].residual.describe()\n",
    "#calculating IQR using Q3 and Q1 and using IQR to calculate the upper and lower bound using the formula above\n",
    "iqr_bk = vis_bk[6]-vis_bk[4]\n",
    "ub_bk = vis_bk[6] + 1.5*iqr_bk\n",
    "lb_bk = vis_bk[4] - 1.5*iqr_bk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we have calculated the upper bound and lower bound values of residual for each branch type we can filter the rows with outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the indexes for rows with redisual outliers with value more than upper bound and less than lower bound for branch 'NS'\n",
    "o_ns = outlier_data[(outlier_data['branch_code']=='NS') & ((outlier_data['residual'] > ub_ns) | (outlier_data['residual'] < lb_ns))].index.values.astype(int)\n",
    "\n",
    "#storing the indexes for rows with redisual outliers with value more than upper bound and less than lower bound for branch 'TP'\n",
    "o_tp = outlier_data[(outlier_data['branch_code']=='TP') & ((outlier_data['residual'] > ub_tp) | (outlier_data['residual'] < lb_tp))].index.values.astype(int)\n",
    "\n",
    "#storing the indexes for rows with redisual outliers with value more than upper bound and less than lower bound for branch 'BK'\n",
    "o_bk = outlier_data[(outlier_data['branch_code']=='BK') & ((outlier_data['residual'] > ub_bk) | (outlier_data['residual'] < lb_bk))].index.values.astype(int)\n",
    "\n",
    "#the above variables carry the indexes in the form of a one-d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will convert the array into list and then perform concatination to get a final list of rows with outliers\n",
    "index = list(o_ns) + list(o_tp) + list(o_bk)\n",
    "len(index)\n",
    "#in total there are 20 outtlier values which needs to be removed, \n",
    "\n",
    "#droping all the rows with index in list using drop function\n",
    "outlier_data = outlier_data.drop(index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 480 entries, 0 to 499\n",
      "Data columns (total 15 columns):\n",
      "order_id                   480 non-null object\n",
      "date                       480 non-null object\n",
      "time                       480 non-null object\n",
      "order_type                 480 non-null object\n",
      "branch_code                480 non-null object\n",
      "order_items                480 non-null object\n",
      "order_price                480 non-null float64\n",
      "customer_lat               480 non-null float64\n",
      "customer_lon               480 non-null float64\n",
      "customerHasloyalty?        480 non-null int64\n",
      "distance_to_customer_KM    480 non-null float64\n",
      "delivery_fee               480 non-null float64\n",
      "time_of_day                480 non-null int64\n",
      "weekend_weekday            480 non-null int64\n",
      "residual                   480 non-null float64\n",
      "dtypes: float64(6), int64(3), object(6)\n",
      "memory usage: 60.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#after droping 20 rows with outliers, we left with 480\n",
    "outlier_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers have been removed , now we drop the extra columns we added and later save it into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data=outlier_data.drop(['time_of_day','weekend_weekday','residual'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data.to_csv('Group154_outlier_data_solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing the missing values in the missing_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      "order_id                   500 non-null object\n",
      "date                       500 non-null object\n",
      "time                       500 non-null object\n",
      "order_type                 500 non-null object\n",
      "branch_code                400 non-null object\n",
      "order_items                500 non-null object\n",
      "order_price                500 non-null float64\n",
      "customer_lat               500 non-null float64\n",
      "customer_lon               500 non-null float64\n",
      "customerHasloyalty?        500 non-null int64\n",
      "distance_to_customer_KM    450 non-null float64\n",
      "delivery_fee               450 non-null float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "missing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there are:\n",
    "* 100 values missing in the branch_code\n",
    "* 50 values missing in the customerHasloyalty?\n",
    "* 50 values missing in the delivery_fee\n",
    "\n",
    "<b>We first impute the missing_values in branch_code</b>. We know that branch_code and order_id have some relation. From the outlier_data we extracted the 3 lists corresponding to different branches. We will do the same sort of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "\n",
    "for n,j in missing_data.iterrows():\n",
    "    if pd.isnull(j['branch_code']): # .isnull() will check wherever the branch_code is null\n",
    "        \n",
    "        #if first 4 charcters of order_id are in the list\n",
    "        # then assign 'NS' to the corresponding branch_code\n",
    "        if j['order_id'][0:4] in ['ORDZ', 'ORDC', 'ORDI']:\n",
    "            missing_data.iloc[n,4]='NS'\n",
    "            \n",
    "        #if first 4 charcters of order_id are in the list\n",
    "        # then assign 'TP' to the corresponding branch_code      \n",
    "        if j['order_id'][0:4] in ['ORDY', 'ORDJ', 'ORDB']:\n",
    "            missing_data.iloc[n,4]='TP'\n",
    "            \n",
    "        #if first 4 charcters of order_id are in the list\n",
    "        # then assign 'BK' to the corresponding branch_code\n",
    "        if j['order_id'][0:4] in ['ORDK', 'ORDX', 'ORDA']:\n",
    "            missing_data.iloc[n,4]='BK'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Imputing the missing values is distance_to_customer_KM\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to merge the dataframes and we do it by using merge. \"pd.merge\" merges two DataFrames or named Series objects with a database-style join. We first perform a left join on missing_data and nodes_data so that to corresponding customer lat and lon we get the correct customer nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = pd.merge(left=missing_data,right=nodes_data, how='left', left_on=['customer_lat','customer_lon'], right_on=['lat','lon'])\n",
    "#we are merging on the same dataframe\n",
    "\n",
    "missing_data=missing_data.drop(columns=['lat','lon'])\n",
    "missing_data=missing_data.rename(columns={'node':'customer_node'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is an error in the nodes.csv file as get 502 rows after joining(left join) the two dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                   502\n",
       "date                       502\n",
       "time                       502\n",
       "order_type                 502\n",
       "branch_code                502\n",
       "order_items                502\n",
       "order_price                502\n",
       "customer_lat               502\n",
       "customer_lon               502\n",
       "customerHasloyalty?        502\n",
       "distance_to_customer_KM    452\n",
       "delivery_fee               452\n",
       "customer_node              502\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try to find out where the errors are so that we do not get further problems. We find out that there are 2 extra rows for the same order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORDJ06473    3\n",
       "ORDC01603    1\n",
       "ORDA03332    1\n",
       "Name: order_id, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data.order_id.value_counts().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We look into this order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>customer_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>ORDJ06473</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>16:47:19</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salmon', 3), ('Fish&amp;Chips', 8), ('Shrimp', ...</td>\n",
       "      <td>811.5</td>\n",
       "      <td>-37.819726</td>\n",
       "      <td>144.969655</td>\n",
       "      <td>0</td>\n",
       "      <td>8.164</td>\n",
       "      <td>12.49497</td>\n",
       "      <td>243963290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>ORDJ06473</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>16:47:19</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salmon', 3), ('Fish&amp;Chips', 8), ('Shrimp', ...</td>\n",
       "      <td>811.5</td>\n",
       "      <td>-37.819726</td>\n",
       "      <td>144.969655</td>\n",
       "      <td>0</td>\n",
       "      <td>8.164</td>\n",
       "      <td>12.49497</td>\n",
       "      <td>6182893637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>ORDJ06473</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>16:47:19</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salmon', 3), ('Fish&amp;Chips', 8), ('Shrimp', ...</td>\n",
       "      <td>811.5</td>\n",
       "      <td>-37.819726</td>\n",
       "      <td>144.969655</td>\n",
       "      <td>0</td>\n",
       "      <td>8.164</td>\n",
       "      <td>12.49497</td>\n",
       "      <td>6182893638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id        date      time order_type branch_code  \\\n",
       "394  ORDJ06473  2018-09-25  16:47:19     Dinner          TP   \n",
       "395  ORDJ06473  2018-09-25  16:47:19     Dinner          TP   \n",
       "396  ORDJ06473  2018-09-25  16:47:19     Dinner          TP   \n",
       "\n",
       "                                           order_items  order_price  \\\n",
       "394  [('Salmon', 3), ('Fish&Chips', 8), ('Shrimp', ...        811.5   \n",
       "395  [('Salmon', 3), ('Fish&Chips', 8), ('Shrimp', ...        811.5   \n",
       "396  [('Salmon', 3), ('Fish&Chips', 8), ('Shrimp', ...        811.5   \n",
       "\n",
       "     customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "394    -37.819726    144.969655                    0                    8.164   \n",
       "395    -37.819726    144.969655                    0                    8.164   \n",
       "396    -37.819726    144.969655                    0                    8.164   \n",
       "\n",
       "     delivery_fee  customer_node  \n",
       "394      12.49497      243963290  \n",
       "395      12.49497     6182893637  \n",
       "396      12.49497     6182893638  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data[missing_data['order_id']=='ORDJ06473']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is strange to see such kind of scenario where for 3 different nodes we have same latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>243963290</td>\n",
       "      <td>-37.819726</td>\n",
       "      <td>144.969655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>6182893637</td>\n",
       "      <td>-37.819726</td>\n",
       "      <td>144.969655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>6182893638</td>\n",
       "      <td>-37.819726</td>\n",
       "      <td>144.969655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             node        lat         lon\n",
       "5320    243963290 -37.819726  144.969655\n",
       "12603  6182893637 -37.819726  144.969655\n",
       "12604  6182893638 -37.819726  144.969655"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_data[(nodes_data['node']== 243963290) | (nodes_data['node']== 6182893637) | (nodes_data['node']== 6182893638)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We drop the two rows 395 and 396 from our outlier_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = missing_data.drop([395,396],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                   500\n",
       "date                       500\n",
       "time                       500\n",
       "order_type                 500\n",
       "branch_code                500\n",
       "order_items                500\n",
       "order_price                500\n",
       "customer_lat               500\n",
       "customer_lon               500\n",
       "customerHasloyalty?        500\n",
       "distance_to_customer_KM    450\n",
       "delivery_fee               450\n",
       "customer_node              500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it looks better\n",
    "Since we already have a datframe branches 1 which have its code and node. We now need to perform left join on branches1 and outlier_data so that to to corresponding branch code we get correct branch node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data=pd.merge(left=missing_data,right=branches1, how='left', left_on=['branch_code'], right_on=['branch_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now can apply Djisktra algorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = missing_data['branch_node']  #storing each 'branch_code' in source from the dirty_data\n",
    "target = missing_data['customer_node']  #storing each 'customer_code' in target from the dirty_data\n",
    "\n",
    "temp_list2=list(zip(source,target)) #zipping the variables and storing them in list\n",
    "dist1=[] #empty list\n",
    "\n",
    "for a,b in temp_list2:\n",
    "    dist1.append(networkx.dijkstra_path_length(G,a,b))\n",
    "    #dijkstra_path_length returns the shortest path length from source to target in a weighted graph.\n",
    "    #appending all the distances to the list dist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The distance we calculated is in metres and we need to convert it into km since the distance_to_customer_KM is given in kms.\n",
    "#we divide each item of the list by 1000 using for loop and appending the new items into new list 'dis_out'\n",
    "\n",
    "dis_out=[] #empty list\n",
    "for x in dist1:\n",
    "    dis_out.append(x/1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterrows() function will loop through each row of a dataframe as (index, series) pairs\n",
    "#for loop along with iterrows will help to iterate thrrough each row one by one.\n",
    "\n",
    "for n,j in missing_data.iterrows():\n",
    "    if pd.isnull(j['distance_to_customer_KM']): #.isnull() will check wherever the distance_to_customer_KM is null\n",
    "        missing_data.iloc[n,10]=dis_out[n]      # and we will then assign the distance we calculated at the missing places\n",
    "                                                # n is the index of the row and index of the dis_out as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values in the delivery fee column\n",
    "\n",
    "We first need to add 2 columns in similar way we added above to missing_data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to missing_data with all values assigned to 0.\n",
    "missing_data['time_of_day']=[0]*missing_data.shape[0]\n",
    "\n",
    "for a,b in missing_data.iterrows():\n",
    "    meal=b['order_type']\n",
    "    \n",
    "    #if meal is equal to Breakfast then assinging value 0 to the column 'time_of_day'\n",
    "    if meal=='Breakfast':\n",
    "        missing_data.iloc[a,14]=0\n",
    "        \n",
    "    #if meal is equal to Lunch then assinging value 1 to the column 'time_of_day'\n",
    "    if meal=='Lunch':\n",
    "        missing_data.iloc[a,14]=1\n",
    "        \n",
    "    #if meal is equal to Dinner then assinging value 2 to the column 'time_of_day'\n",
    "    if meal =='Dinner':\n",
    "        missing_data.iloc[a,14]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to missing_data with all values assigned to 0.\n",
    "missing_data['weekend_weekday']=[0]*missing_data.shape[0]\n",
    "\n",
    "for a,b in missing_data.iterrows():\n",
    "    time=b['date']\n",
    "    \n",
    "    df = pd.Timestamp(time)\n",
    "    day=df.dayofweek\n",
    "    \n",
    "    \n",
    "    #if it is a weekday( 0,1,2,3,4) then assigning the value 0 to the column 'weekend_weekday'\n",
    "    if (day==0) or (day==1) or (day==1) or (day==2) or (day==3) or (day==4):\n",
    "        missing_data.iloc[a,15]=0\n",
    "        \n",
    "    #if it is a weekend(5,6) then assigning the value 1 to the column 'weekend_weekday\n",
    "    if (day==5) or (day==6):\n",
    "        missing_data.iloc[a,15]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same 3 models we created from the missing_data_mod and we predict the values for delivery fee in the missing_data. After predicting we will first check whether the customer has loyalty or not. IF loyalty is 0 then we will assign the predicted value and if loyalty is 1 , then we will assign the (predicted value/2) since loyalty being 1 means customer has 50% off on the delievry fee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in missing_data.iterrows():\n",
    "    #performing iteration on every row of the data to check and fill the missing values of the delivery fee\n",
    "    lo = y['customerHasloyalty?']\n",
    "    #customer loyalty is stored in variable named 'lo' used to predict the delivery charge and provide discount \n",
    "    code=y['branch_code']\n",
    "    #branch code is saved in 'code' variable used to use the respective model for prediction\n",
    "    di=y['distance_to_customer_KM']\n",
    "    #distance is stored to calculate the delivery fee\n",
    "    t=y['time_of_day']\n",
    "    ww=y['weekend_weekday']\n",
    "    #time of day and weekday used in prediction model is stored in variable t and ww\n",
    "    \n",
    "    #if the value of delivery fee is null(missing) we will fill it using our prediction model\n",
    "    if pd.isnull(j['delivery_fee']):\n",
    "    \n",
    "        if code=='NS':\n",
    "            #for null delivery fee for branch with branch code 'NS'\n",
    "            p_ns=lm_ns.predict(np.array([[di,t,ww]])) #using model 'lm_ns' tp predict the fee using distance, day time and weekday\n",
    "            if lo==0:\n",
    "            #if customer loyalty is zero, no discount applied and delivery fee will be as predicted\n",
    "                missing_data.iloc[x,11] = p_ns\n",
    "            else:\n",
    "                #otherwise, customers with loyalty card will get 50% dicsount on delivery fee\n",
    "                missing_data.iloc[x,11] = p_ns/2\n",
    "    \n",
    "        if code=='TP':\n",
    "            #for null delivery fee for branch with branch code 'TP'\n",
    "            p_tp=lm_tp.predict(np.array([[di,t,ww]]))\n",
    "            if lo==0:\n",
    "                #if customer loyalty is zero, no discount applied and delivery fee will be as predicted\n",
    "                missing_data.iloc[x,11] = p_tp\n",
    "            else:\n",
    "                #otherwise, customers with loyalty card will get 50% dicsount on delivery fee\n",
    "                missing_data.iloc[x,11] = p_tp/2\n",
    "        \n",
    "        if code=='BK':\n",
    "            #for null delivery fee for branch with branch code 'BK'\n",
    "            p_bk=lm_bk.predict(np.array([[di,t,ww]]))\n",
    "            if lo==0:\n",
    "                #if customer loyalty is zero, no discount applied and delivery fee will be as predicted\n",
    "                missing_data.iloc[x,11] = p_bk\n",
    "            else:\n",
    "                #otherwise, customers with loyalty card will get 50% dicsount on delivery fee\n",
    "                missing_data.iloc[x,11] = p_bk/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing values have been imputed , now we drop the extra columns we added and then we save the dataframe to into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data=missing_data.drop(['time_of_day','weekend_weekday','customer_node','branch_node'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.to_csv('Group154_outlier_data_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORDC06762</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>13:54:55</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Burger', 7), ('Steak', 2), ('Salad', 4)]</td>\n",
       "      <td>375.8</td>\n",
       "      <td>-37.803909</td>\n",
       "      <td>144.957357</td>\n",
       "      <td>0</td>\n",
       "      <td>5.380</td>\n",
       "      <td>12.765431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORDK08784</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>09:10:59</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Cereal', 10), ('Pancake', 8)]</td>\n",
       "      <td>404.0</td>\n",
       "      <td>-37.814946</td>\n",
       "      <td>144.964766</td>\n",
       "      <td>0</td>\n",
       "      <td>7.655</td>\n",
       "      <td>11.595206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORDZ03927</td>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>15:16:03</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Steak', 2), ('Fries', 7), ('Chicken', 7)]</td>\n",
       "      <td>398.0</td>\n",
       "      <td>-37.803134</td>\n",
       "      <td>144.961925</td>\n",
       "      <td>0</td>\n",
       "      <td>7.090</td>\n",
       "      <td>12.359811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORDZ06176</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>19:39:43</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pasta', 2), ('Salmon', 9)]</td>\n",
       "      <td>424.0</td>\n",
       "      <td>-37.812911</td>\n",
       "      <td>144.933698</td>\n",
       "      <td>0</td>\n",
       "      <td>8.905</td>\n",
       "      <td>14.997308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORDJ05346</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>15:46:28</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Salad', 10), ('Fries', 10), ('Burger', 3)]</td>\n",
       "      <td>385.0</td>\n",
       "      <td>-37.803353</td>\n",
       "      <td>144.951851</td>\n",
       "      <td>0</td>\n",
       "      <td>9.815</td>\n",
       "      <td>12.773022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id        date      time order_type branch_code  \\\n",
       "0  ORDC06762  2018-07-01  13:54:55      Lunch          NS   \n",
       "1  ORDK08784  2018-02-05  09:10:59  Breakfast          BK   \n",
       "2  ORDZ03927  2018-08-07  15:16:03      Lunch          NS   \n",
       "3  ORDZ06176  2018-12-20  19:39:43     Dinner          NS   \n",
       "4  ORDJ05346  2018-08-24  15:46:28      Lunch          TP   \n",
       "\n",
       "                                     order_items  order_price  customer_lat  \\\n",
       "0    [('Burger', 7), ('Steak', 2), ('Salad', 4)]        375.8    -37.803909   \n",
       "1               [('Cereal', 10), ('Pancake', 8)]        404.0    -37.814946   \n",
       "2   [('Steak', 2), ('Fries', 7), ('Chicken', 7)]        398.0    -37.803134   \n",
       "3                  [('Pasta', 2), ('Salmon', 9)]        424.0    -37.812911   \n",
       "4  [('Salad', 10), ('Fries', 10), ('Burger', 3)]        385.0    -37.803353   \n",
       "\n",
       "   customer_lon  customerHasloyalty?  distance_to_customer_KM  delivery_fee  \n",
       "0    144.957357                    0                    5.380     12.765431  \n",
       "1    144.964766                    0                    7.655     11.595206  \n",
       "2    144.961925                    0                    7.090     12.359811  \n",
       "3    144.933698                    0                    8.905     14.997308  \n",
       "4    144.951851                    0                    9.815     12.773022  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

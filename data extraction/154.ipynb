{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1\n",
    "#### Student Names and Student Id : Akshay Rai Chopra(30228751) and  Parul (29507960)\n",
    "#### Group Number: 154\n",
    "\n",
    "Date: 20/08/2019\n",
    "\n",
    "Version: 2.0\n",
    "\n",
    "Environment: Python 3.6.0 and Anaconda 4.3.0 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "\n",
    "* pandas 0.19.2 (for data frame, included in Anaconda Python 3.6) \n",
    "* re 2.2.1 (for regular expression, included in Anaconda Python 3.6) \n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "This assignment comprises the execution of different text processing and analysis tasks applied to patent documents in XML format. There are a total of 150 patents in one file named `Group154.txt`.\n",
    "\n",
    "This assessment touches the very first step of analyzing textual data, i.e., extracting data from semi-structured text files\n",
    "\n",
    "The data-set contains information about several patent grants, e.g., patent title, patent ID, citation network, abstract etc. (see sample_input.txt). Your task is to extract the data and transform the data into the CSV and JSON format with the following elements:\n",
    "1. grant_id: a unique ID for a patent grant consisting of alphanumeric characters.\n",
    "2. patent_kind: a category to which the patent grant belongs.\n",
    "3. patent_title: a title given by the inventor to the patent claim.\n",
    "4. number_of_claims: an integer denoting the number of claims for a given grant.\n",
    "5. citations_examiner_count: an integer denoting the number of citations made by the examiner for a given patent grant (0 if None)\n",
    "6. citations_applicant_count: an integer denoting the number of citations made by the applicant for a given patent grant (0 if None)\n",
    "7. inventors: a list of the patent inventors’ names ([NA] if the value is Null).\n",
    "8. claims_text: a list of claim texts for the different patent claims ([NA] if the value is Null).\n",
    "9. abstract: the patent abstract text (‘NA’ if the value is Null)\n",
    "\n",
    "More details for each task will be given in the following sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examining and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, the file `Group154.txt` will be loaded so its first 10 lines can be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<us-patent-grant lang=\"EN\" dtd-version=\"v4.5 2014-04-03\" file=\"US10361682-20190723.XML\" status=\"PRODUCTION\" id=\"us-patent-grant\" country=\"US\" date-produced=\"20190709\" date-publ=\"20190723\">\n",
      "<us-bibliographic-data-grant>\n",
      "<publication-reference>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>10361682</doc-number>\n",
      "<kind>B2</kind>\n",
      "<date>20190723</date>\n",
      "</document-id>\n"
     ]
    }
   ],
   "source": [
    "# print first ten lines of the file\n",
    "with open('Group154.txt','r') as infile:\n",
    "    print('\\n'.join([infile.readline().strip() for i in range(0, 10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first XML document has an XML declaration `<?xml...?>` and a root tag `<us-patent-grant>`. Based on this information it's possible to properly delimit an XML document so it can be extracted individually.\n",
    "\n",
    "A regex is defined so strings starting with an XML declaration `<?xml` and ending with the closing tag `</us-patent-grant>` are captured individually. The non-greedy pattern `*?` is necessary so the whole file is not matched. The regex also uses the pattern `[\\s\\S]` (white space or non white space characters) which causes to capture everything, even line breaks, between the XML declaration and the closing tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read the whole file\n",
    "with open('Group154.txt','r') as infile:\n",
    "    text = infile.read() \n",
    "\n",
    "# matches everything between the XML declaration and the root closing tag\n",
    "regex = r'<\\?xml[\\s\\S]*?</us-patent-grant>' \n",
    "patents = re.findall(regex, text)\n",
    "print(len(patents))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The result is a list of strings ('patents') with length 150. All patents haven been successfully extracted from the main file. Now let's fetch the results of given tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parsing and extracting the data \n",
    "\n",
    "The first task is to define the regular expressions so that we can capture the desired strings. There is regular expression cheatsheet:\n",
    "\n",
    "<h4> Special Characters</h4>\n",
    "\n",
    "\\\t- escape special characters\n",
    "\n",
    ".\t- matches any character\n",
    "\n",
    "^\t- matches beginning of string \n",
    "\n",
    "$\t- matches end of string\n",
    "\n",
    "()\t- creates a capture group and indicates precedence  \n",
    "\n",
    "<h4> Quantifiers </h4>\n",
    "\n",
    "$*$\t- 0 or more (append ? for non-greedy)  \n",
    "\n",
    "$+$\t- 1 or more (append ? for non-greedy)  \n",
    "\n",
    "?\t- 0 or 1 (append ? for non-greedy)\n",
    "\n",
    "<h4> Special Sequences </h4>\n",
    "\n",
    "\\d\t- digit\n",
    "\n",
    "\\D\t- non-digit\n",
    "\n",
    "\\s\t- whitespace: [ \\t\\n\\r\\f\\v]\n",
    "\n",
    "\\S\t- non-whitespace\n",
    "\n",
    "\\w\t- alphanumeric: [0-9a-zA-Z_]\n",
    "\n",
    "\\W\t- non-alphanumeric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the regular expressions.\n",
    "#re.DOTALL - '.' special character match any character at all, including a newline.\n",
    "\n",
    "reg_grantid=r'<us-p.*(US\\w+)'\n",
    "\n",
    "reg_patent_title=r'<invention.*>(.*)<'\n",
    "\n",
    "reg_no_claims=r'<nu.*claims>(\\d+)<'\n",
    "\n",
    "reg_lname=re.compile('<inventor .*?<last-name>(.*?)<\\/',re.DOTALL)\n",
    "\n",
    "reg_fname=re.compile('<inventor .*?<first-name>(.*?)<\\/',re.DOTALL)\n",
    "\n",
    "reg_applicant=r'<category>(.*t)<'\n",
    "\n",
    "reg_examiner=r'<category>(.*r)<'\n",
    "\n",
    "reg_claim=re.compile('<claim id.*?>(.*?)<\\/claim>',re.DOTALL)\n",
    "\n",
    "tags=r'<.*?>'\n",
    "\n",
    "reg_abstract=r'<p id=\"p.*\"0000\">(.*)<\\/p>'\n",
    "\n",
    "reg_app_type=r'<ap.*\"(.*)\">'\n",
    "\n",
    "reg_kind=r'<kind>(.*)<\\/kind>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will capture the desired strings with the above defined regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#creating an empty list and an empty dictionary \n",
    "data2=[]\n",
    "dic={}\n",
    "\n",
    "#with the help of for loop, one patent details are passed at a time and the following extractions are performed. \n",
    "for i in patents:\n",
    "    \n",
    "    #storing the captured string in grant_id\n",
    "    grant_id = str(''.join(re.findall(reg_grantid, i)))            \n",
    "    \n",
    "    #storing the captured string in patent_title and replacing the special characters with the single space. \n",
    "    patent_title = str(''.join(re.findall(reg_patent_title, i)))   \n",
    "    patent_title = re.sub('&#x\\d*;',' ',patent_title)\n",
    "    \n",
    "    \n",
    "    #storing the captured string in app_type and applying conditions in order to get the desired string and then saving it in kind\n",
    "    app_type = str(''.join(re.findall(reg_app_type, i)))\n",
    "    if app_type =='design':\n",
    "        kind = 'Design Patent'\n",
    "    elif app_type =='reissue':\n",
    "        kind = 'Reissue Patent'\n",
    "    elif app_type =='plant': \n",
    "        if re.findall(reg_kind, i)[0]=='P2':\n",
    "            kind='Plant Patent Grant (no published application) issued on or after January 2, 2001.'\n",
    "        elif re.findall(reg_kind, i)[0]=='P3':\n",
    "            kind='Plant Patent Grant (with a published application) issued on or after January 2, 2001.'\n",
    "    elif app_type =='utility':        \n",
    "        if re.findall(reg_kind, i)[0]=='B1':\n",
    "            kind='Utility Patent Grant (no published application) issued on or after January 2, 2001.'\n",
    "        elif re.findall(reg_kind, i)[0]=='B2':\n",
    "            kind='Utility Patent Grant (with a published application) issued on or after January 2, 2001.'\n",
    "    \n",
    "    #extracting the no_of_claims and converting into string\n",
    "    no_of_claims = str(''.join(re.findall(reg_no_claims, i)))\n",
    "    \n",
    "    #joining the captured data(fname and lname) and then storing it in inventors in the form of string\n",
    "    fname=re.findall(reg_fname, i)\n",
    "    lname=re.findall(reg_lname, i)\n",
    "    inventor=[]\n",
    "    for x in range(len(fname)):\n",
    "        inventor.append(fname[x]+\" \"+lname[x])\n",
    "    inventors = '['+str(','.join(inventor))+']'\n",
    "    inventors = re.sub('&#x\\w*;','',inventors)\n",
    "    if inventors =='[]':\n",
    "        inventors = '[NA]'\n",
    "    \n",
    "    \n",
    "    \n",
    "    #counting the number of citations made by applicant and examiner\n",
    "    citations_applicant_count = len(re.findall(reg_applicant, i))\n",
    "    citations_examiner_count = len(re.findall(reg_examiner, i))\n",
    "    \n",
    "    #extracting the claim text and removing the tags, new line and special characters.\n",
    "    claims_text = ','.join(re.findall(reg_claim, i))\n",
    "    claims_text = re.sub(tags,'',claims_text)\n",
    "    claims_text = re.sub('\\n','',claims_text)\n",
    "    claims_text = '['+ re.sub('&#x\\w*;','',claims_text)+']'\n",
    "    if claims_text =='':\n",
    "        claims_text = 'NA'\n",
    "        \n",
    "    #extracting the abstract text and removing the tags and special characters and if abstract is missing, writing 'NA' in place\n",
    "    abstract = str(''.join(re.findall(reg_abstract, i)))\n",
    "    abstract = re.sub(tags,'',abstract)\n",
    "    abstract = re.sub('&#x\\w*;',' ',abstract)\n",
    "    if abstract =='':\n",
    "        abstract = 'NA'\n",
    "    \n",
    "    data1=[grant_id,patent_title,kind,no_of_claims,inventors,citations_applicant_count,citations_examiner_count,claims_text,abstract]\n",
    "    data2.append(data2)\n",
    "    \n",
    "    #creating a dictionary with 'grant_id' as key and other dictionary with remaining data as values.\n",
    "    dic[grant_id]={'patent_title':patent_title,'kind':kind,'no_of_claims':no_of_claims,'inventors':inventors,'citations_applicant_count':citations_applicant_count,'citations_examiner_count':citations_examiner_count,'claims_text':claims_text,'abstract':abstract}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transforming the extracted data into the CSV and JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe from the list\n",
    "df=pd.DataFrame(data2,columns=['grant_id','patent_title','kind','number_of_claims','inventors','citations_applicant_count','citations_examiner_count','claims_text','abstract'])\n",
    "\n",
    "#exporting tha pandas dataframe into csv file.\n",
    "df.set_index('grant_id',inplace=True)\n",
    "df.to_csv('154.csv')\n",
    "\n",
    "#creating the new file and writing the data in the json file.\n",
    "with open ('154.json','w') as outfile:\n",
    "    outfile.write(str(dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assessment measured the understanding of basic text file processing techniques in the Python programming language. The main outcomes achieved while applying these techniques were:\n",
    "\n",
    "1. **Applying regular expressions** - Using the regex to capture the desired information. \n",
    "2. **Parsing and extracting the data** - With the help of functions like findall() and len(), it was possible to access hierarchical data with only a few inspections. Luckily, the use of Python's functions like join() and in-line iterators made such tasks more easy and readable.\n",
    "3. **DataFrame manipulation** - By using the pandas package, importing dictinary into data frames was quite straightforward. \n",
    "4. **Exporting data to specific format like CSV and JSON** -  By using built-in functions like DataFrame.to_csv() it was possible to export data frames into .csv files without additional formatting and transformations. In other cases, native file operations like open() and write() were required where data had to be processed line by line. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
